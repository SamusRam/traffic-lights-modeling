{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 lines\n",
      "#1: python3.7/codeop.py:141: 7.2 KiB\n",
      "    codeob = compile(source, filename, symbol, self.flags, 1)\n",
      "#2: <ipython-input-2-ca8240b77984>:62: 0.4 KiB\n",
      "    snapshot = tracemalloc.take_snapshot()\n",
      "#3: core/interactiveshell.py:3417: 0.4 KiB\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "#4: <ipython-input-2-ca8240b77984>:35: 0.1 KiB\n",
      "    def display_top(snapshot, key_type='lineno', limit=20):\n",
      "#5: core/interactiveshell.py:3337: 0.1 KiB\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "#6: core/interactiveshell.py:117: 0.1 KiB\n",
      "    Module = lambda nodelist, type_ignores: OriginalModule(nodelist)\n",
      "#7: core/compilerop.py:150: 0.0 KiB\n",
      "    self.flags &= ~turn_on_bits\n",
      "#8: core/interactiveshell.py:3331: 0.0 KiB\n",
      "    mod = Module([node], [])\n",
      "Total allocated size: 8.4 KiB\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../scripts')\n",
    "from l5kit_modified.l5kit_modified import FramesDataset, create_chopped_dataset, AgentDatasetModified, get_agent_indices_set\n",
    "from kalman import KalmanTrackerPredictor\n",
    "from lane_processing import *\n",
    "import pickle\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pytz import timezone\n",
    "from datetime import datetime, timedelta\n",
    "from l5kit.data.filter import filter_tl_faces_by_status\n",
    "from workalendar.usa import CaliforniaSanFrancisco\n",
    "import pandas as pd\n",
    "import json\n",
    "from django.core.serializers.json import DjangoJSONEncoder\n",
    "\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "import multiprocessing as mp\n",
    "import tracemalloc\n",
    "import linecache\n",
    "from functools import partial\n",
    "tracemalloc.start()\n",
    "\n",
    "def display_top(snapshot, key_type='lineno', limit=20):\n",
    "    snapshot = snapshot.filter_traces((\n",
    "        tracemalloc.Filter(False, \"<frozen importlib._bootstrap>\"),\n",
    "        tracemalloc.Filter(False, \"<unknown>\"),\n",
    "    ))\n",
    "    top_stats = snapshot.statistics(key_type)\n",
    "\n",
    "    print(\"Top %s lines\" % limit)\n",
    "    for index, stat in enumerate(top_stats[:limit], 1):\n",
    "        frame = stat.traceback[0]\n",
    "        # replace \"/path/to/module/file.py\" with \"module/file.py\"\n",
    "        filename = os.sep.join(frame.filename.split(os.sep)[-2:])\n",
    "        print(\"#%s: %s:%s: %.1f KiB\"\n",
    "              % (index, filename, frame.lineno, stat.size / 1024))\n",
    "        line = linecache.getline(frame.filename, frame.lineno).strip()\n",
    "        if line:\n",
    "            print('    %s' % line)\n",
    "\n",
    "    other = top_stats[limit:]\n",
    "    if other:\n",
    "        size = sum(stat.size for stat in other)\n",
    "        print(\"%s other: %.1f KiB\" % (len(other), size / 1024))\n",
    "    total = sum(stat.size for stat in top_stats)\n",
    "    print(\"Total allocated size: %.1f KiB\" % (total / 1024))\n",
    "\n",
    "\n",
    "\n",
    "snapshot = tracemalloc.take_snapshot()\n",
    "display_top(snapshot)\n",
    "\n",
    "%matplotlib inline\n",
    "    \n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = \"../input/\"\n",
    "\n",
    "import zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_seq_df = pd.read_hdf('../input/lane_seq_df.hdf5', key='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>hist_seq</th>\n",
       "      <th>future_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>((bUGp, 0.2222222222222222, 2, 22.188255, 0.033309937, 0, nan, nan), (sRCY, 0.4444444444444444, 1, 22.307493, 0.0, 0, nan, nan))</td>\n",
       "      <td>(bUGp, sRCY, O5jj)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>328</td>\n",
       "      <td>((bUGp, 0.2222222222222222, 2, 22.188255, 0.033309937, 0, nan, nan), (sRCY, 0.4444444444444444, 1, 22.307493, 0.0, 0, nan, nan), (O5jj, 0.7692307692307693, 2, 22.45031, 0.04981613, 0, nan, nan))</td>\n",
       "      <td>(bUGp, sRCY, O5jj, sRCY)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>328</td>\n",
       "      <td>((bUGp, 0.2222222222222222, 2, 22.188255, 0.033309937, 0, nan, nan), (sRCY, 0.4444444444444444, 1, 22.307493, 0.0, 0, nan, nan), (O5jj, 0.7692307692307693, 2, 22.45031, 0.04981613, 0, nan, nan))</td>\n",
       "      <td>(bUGp, sRCY, O5jj, sRCY)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>328</td>\n",
       "      <td>((bUGp, 0.2222222222222222, 2, 22.188255, 0.033309937, 0, nan, nan), (sRCY, 0.4444444444444444, 1, 22.307493, 0.0, 0, nan, nan), (O5jj, 0.7692307692307693, 2, 22.45031, 0.04981613, 0, nan, nan))</td>\n",
       "      <td>(bUGp, sRCY, O5jj, sRCY)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>328</td>\n",
       "      <td>((bUGp, 0.2222222222222222, 2, 22.188255, 0.033309937, 0, nan, nan), (sRCY, 0.4444444444444444, 1, 22.307493, 0.0, 0, nan, nan), (O5jj, 0.7692307692307693, 2, 22.45031, 0.04981613, 0, nan, nan))</td>\n",
       "      <td>(bUGp, sRCY, O5jj, sRCY)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id  \\\n",
       "0       328   \n",
       "1       328   \n",
       "2       328   \n",
       "3       328   \n",
       "4       328   \n",
       "\n",
       "                                                                                                                                                                                             hist_seq  \\\n",
       "0                                                                    ((bUGp, 0.2222222222222222, 2, 22.188255, 0.033309937, 0, nan, nan), (sRCY, 0.4444444444444444, 1, 22.307493, 0.0, 0, nan, nan))   \n",
       "1  ((bUGp, 0.2222222222222222, 2, 22.188255, 0.033309937, 0, nan, nan), (sRCY, 0.4444444444444444, 1, 22.307493, 0.0, 0, nan, nan), (O5jj, 0.7692307692307693, 2, 22.45031, 0.04981613, 0, nan, nan))   \n",
       "2  ((bUGp, 0.2222222222222222, 2, 22.188255, 0.033309937, 0, nan, nan), (sRCY, 0.4444444444444444, 1, 22.307493, 0.0, 0, nan, nan), (O5jj, 0.7692307692307693, 2, 22.45031, 0.04981613, 0, nan, nan))   \n",
       "3  ((bUGp, 0.2222222222222222, 2, 22.188255, 0.033309937, 0, nan, nan), (sRCY, 0.4444444444444444, 1, 22.307493, 0.0, 0, nan, nan), (O5jj, 0.7692307692307693, 2, 22.45031, 0.04981613, 0, nan, nan))   \n",
       "4  ((bUGp, 0.2222222222222222, 2, 22.188255, 0.033309937, 0, nan, nan), (sRCY, 0.4444444444444444, 1, 22.307493, 0.0, 0, nan, nan), (O5jj, 0.7692307692307693, 2, 22.45031, 0.04981613, 0, nan, nan))   \n",
       "\n",
       "                 future_seq  \n",
       "0        (bUGp, sRCY, O5jj)  \n",
       "1  (bUGp, sRCY, O5jj, sRCY)  \n",
       "2  (bUGp, sRCY, O5jj, sRCY)  \n",
       "3  (bUGp, sRCY, O5jj, sRCY)  \n",
       "4  (bUGp, sRCY, O5jj, sRCY)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 500)\n",
    "lane_seq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bUGp', '0.2222222222222222', '2', '22.188255', '0.033309937', '0',\n",
       "       'nan', 'nan'], dtype='<U18')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(lane_seq_df['hist_seq'].values[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_seq_df['hist_len']  = lane_seq_df['hist_seq'].map(len)\n",
    "lane_seq_df['future_len']  = lane_seq_df['future_seq'].map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17789881, 24486247)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lane_seq_df['hist_len'].sum(), lane_seq_df['future_len'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPOINT_DTYPE = [\n",
    "    (\"track_id\", np.int64),  \n",
    "    (\"hist_index_interval\", np.int64, (2,)),\n",
    "    (\"future_index_interval\", np.int64, (2,)),\n",
    "]\n",
    "\n",
    "\n",
    "HIST_DTYPE = [\n",
    "    (\"lane_id\", \"<U8\"),\n",
    "    (\"lane_completion_at_start\", np.float32),\n",
    "    (\"number_of_car_observations_on_line\", np.int16),\n",
    "    (\"car_mean_speed_on_line\", np.float32),\n",
    "    (\"car_std_speed_on_line\", np.float32),    \n",
    "    (\"number_of_other_car_observations_on_line\", np.int16),\n",
    "    (\"other_cars_mean_speed_on_line\", np.float32),\n",
    "    (\"other_cars_std_speed_on_line\", np.float32),\n",
    "]\n",
    "\n",
    "FUTURE_DTYPE = [\n",
    "    (\"lane_id\", \"<U8\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_dataset_root = zarr.open_group('../input/lane_seqs.zarr', mode='w')\n",
    "chunk_size = 5000\n",
    "datapoints = lane_dataset_root.require_dataset(\n",
    "            'datapoints', dtype=DATAPOINT_DTYPE, chunks=(chunk_size,), shape=(len(lane_seq_df),)\n",
    "        )\n",
    "hist_seqs = lane_dataset_root.require_dataset(\n",
    "    'hist_seqs', dtype=HIST_DTYPE, chunks=(chunk_size,), shape=(lane_seq_df['hist_len'].sum(),)\n",
    ")\n",
    "future_seqs = lane_dataset_root.require_dataset(\n",
    "    'future_seqs', dtype=FUTURE_DTYPE, chunks=(chunk_size,), shape=(lane_seq_df['future_len'].sum(),)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64eb34b3e65e4b258266188415782f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6696366.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hist_seq_idx = 0\n",
    "future_seq_idx = 0\n",
    "chunk_datapoints_i = 0\n",
    "chunk_datapoints_size = 0\n",
    "chunk_datapoints = np.ndarray(shape=(chunk_size,), dtype=DATAPOINT_DTYPE)\n",
    "chunk_hist_i = 0\n",
    "chunk_hist_size = 0\n",
    "chunk_hist = np.ndarray(shape=(chunk_size,), dtype=HIST_DTYPE)\n",
    "chunk_future_i = 0\n",
    "chunk_future_size = 0\n",
    "chunk_future = np.ndarray(shape=(chunk_size,), dtype=FUTURE_DTYPE)\n",
    "\n",
    "for row_idx, row in tqdm(lane_seq_df.iterrows(), total=len(lane_seq_df)):\n",
    "    chunk_datapoints[chunk_datapoints_size] = ((row['track_id'], (hist_seq_idx, hist_seq_idx + len(row['hist_seq'])), (future_seq_idx, future_seq_idx + len(row['future_seq']))))\n",
    "    chunk_datapoints_size += 1\n",
    "    if chunk_datapoints_size % chunk_size == 0:\n",
    "        datapoints[chunk_datapoints_i*chunk_size: chunk_size*(chunk_datapoints_i + 1)] = chunk_datapoints\n",
    "        chunk_datapoints = np.ndarray(shape=(chunk_size,), dtype=DATAPOINT_DTYPE)\n",
    "        chunk_datapoints_size = 0\n",
    "        chunk_datapoints_i += 1        \n",
    "    \n",
    "    for hist_i, hist_tuple in enumerate(row['hist_seq']):\n",
    "        chunk_hist[chunk_hist_size] = hist_tuple\n",
    "        chunk_hist_size += 1\n",
    "        if chunk_hist_size % chunk_size == 0:\n",
    "            hist_seqs[chunk_hist_i*chunk_size: chunk_size*(chunk_hist_i + 1)] = chunk_hist\n",
    "            chunk_hist_size = 0\n",
    "            chunk_hist = np.ndarray(shape=(chunk_size,), dtype=HIST_DTYPE)\n",
    "            chunk_hist_i += 1\n",
    "            \n",
    "    for future_i, future_line in enumerate(row['future_seq']):\n",
    "        chunk_future[chunk_future_size] = future_line\n",
    "        chunk_future_size += 1\n",
    "        if chunk_future_size % chunk_size == 0:\n",
    "            future_seqs[chunk_future_i*chunk_size: chunk_size*(chunk_future_i + 1)] = chunk_future\n",
    "            chunk_future_size = 0\n",
    "            chunk_future = np.ndarray(shape=(chunk_size,), dtype=FUTURE_DTYPE)\n",
    "            chunk_future_i += 1\n",
    "    hist_seq_idx += len(row['hist_seq'])\n",
    "    future_seq_idx += len(row['future_seq'])\n",
    "    \n",
    "                                   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
