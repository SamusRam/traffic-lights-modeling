{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from l5kit.data import (\n",
    "    TL_FACE_DTYPE,\n",
    "    filter_agents_by_labels,\n",
    "    filter_tl_faces_by_frames,\n",
    "    get_agents_slice_from_frames,\n",
    "    get_tl_faces_slice_from_frames,\n",
    ")\n",
    "from l5kit.data.filter import filter_agents_by_frames, filter_agents_by_track_id\n",
    "from l5kit.geometry import angular_distance, rotation33_as_yaw\n",
    "from l5kit.kinematic import Perturbation\n",
    "from l5kit.sampling.slicing import get_future_slice, get_history_slice\n",
    "from l5kit.rasterization import EGO_EXTENT_HEIGHT, EGO_EXTENT_LENGTH, EGO_EXTENT_WIDTH\n",
    "\n",
    "\n",
    "def generate_agent_sample(\n",
    "    state_index: int,\n",
    "    frames: np.ndarray,\n",
    "    agents: np.ndarray,\n",
    "    tl_faces: np.ndarray,\n",
    "    selected_track_id: Optional[int],\n",
    "    history_num_frames: int,\n",
    "    history_step_size: int,\n",
    "    future_num_frames: int,\n",
    "    future_step_size: int,\n",
    "    filter_agents_threshold: float,\n",
    "    perturbation: Optional[Perturbation] = None,\n",
    ") -> dict:\n",
    "    \"\"\"Generates the inputs and targets to train a deep prediction model. A deep prediction model takes as input\n",
    "    the state of the world (here: an image we will call the \"raster\"), and outputs where that agent will be some\n",
    "    seconds into the future.\n",
    "    This function has a lot of arguments and is intended for internal use, you should try to use higher level classes\n",
    "    and partials that use this function.\n",
    "    Args:\n",
    "        state_index (int): The anchor frame index, i.e. the \"current\" timestep in the scene\n",
    "        frames (np.ndarray): The scene frames array, can be numpy array or a zarr array\n",
    "        agents (np.ndarray): The full agents array, can be numpy array or a zarr array\n",
    "        tl_faces (np.ndarray): The full traffic light faces array, can be numpy array or a zarr array\n",
    "        selected_track_id (Optional[int]): Either None for AV, or the ID of an agent that you want to\n",
    "        predict the future of. This agent is centered in the raster and the returned targets are derived from\n",
    "        their future states.\n",
    "        history_num_frames (int): Amount of history frames to draw into the rasters\n",
    "        history_step_size (int): Steps to take between frames, can be used to subsample history frames\n",
    "        future_num_frames (int): Amount of history frames to draw into the rasters\n",
    "        future_step_size (int): Steps to take between targets into the future\n",
    "        filter_agents_threshold (float): Value between 0 and 1 to use as cutoff value for agent filtering\n",
    "        based on their probability of being a relevant agent\n",
    "        perturbation (Optional[Perturbation]): Object that perturbs the input and targets, used\n",
    "to train models that can recover from slight divergence from training set data\n",
    "    Raises:\n",
    "        ValueError: A ValueError is returned if the specified ``selected_track_id`` is not present in the scene\n",
    "        or was filtered by applying the ``filter_agent_threshold`` probability filtering.\n",
    "    Returns:\n",
    "        dict: a dict object with the raster array, the future offset coordinates (meters),\n",
    "        the future yaw angular offset, the future_availability as a binary mask\n",
    "    \"\"\"\n",
    "    #  the history slice is ordered starting from the latest frame and goes backward in time., ex. slice(100, 91, -2)\n",
    "    history_slice = get_history_slice(state_index, history_num_frames, history_step_size, include_current_state=True)\n",
    "    future_slice = get_future_slice(state_index, future_num_frames, future_step_size)\n",
    "\n",
    "    history_frames = frames[history_slice].copy()  # copy() required if the object is a np.ndarray\n",
    "    future_frames = frames[future_slice].copy()\n",
    "\n",
    "    sorted_frames = np.concatenate((history_frames[::-1], future_frames))  # from past to future\n",
    "\n",
    "    # get agents (past and future)\n",
    "    agent_slice = get_agents_slice_from_frames(sorted_frames[0], sorted_frames[-1])\n",
    "    agents = agents[agent_slice].copy()  # this is the minimum slice of agents we need\n",
    "    history_frames[\"agent_index_interval\"] -= agent_slice.start  # sync interval with the agents array\n",
    "    future_frames[\"agent_index_interval\"] -= agent_slice.start  # sync interval with the agents array\n",
    "    history_agents = filter_agents_by_frames(history_frames, agents)\n",
    "    future_agents = filter_agents_by_frames(future_frames, agents)\n",
    "\n",
    "    try:\n",
    "        tl_slice = get_tl_faces_slice_from_frames(history_frames[-1], history_frames[0])  # -1 is the farthest\n",
    "        # sync interval with the traffic light faces array\n",
    "        history_frames[\"traffic_light_faces_index_interval\"] -= tl_slice.start\n",
    "        history_tl_faces = filter_tl_faces_by_frames(history_frames, tl_faces[tl_slice].copy())\n",
    "    except ValueError:\n",
    "        history_tl_faces = [np.empty(0, dtype=TL_FACE_DTYPE) for _ in history_frames]\n",
    "\n",
    "    if perturbation is not None:\n",
    "        history_frames, future_frames = perturbation.perturb(\n",
    "            history_frames=history_frames, future_frames=future_frames\n",
    "        )\n",
    "\n",
    "    # State you want to predict the future of.\n",
    "    cur_frame = history_frames[0]\n",
    "    cur_agents = history_agents[0]\n",
    "\n",
    "    if selected_track_id is None:\n",
    "        agent_centroid = cur_frame[\"ego_translation\"][:2]\n",
    "        agent_yaw = rotation33_as_yaw(cur_frame[\"ego_rotation\"])\n",
    "        agent_extent = np.asarray((EGO_EXTENT_LENGTH, EGO_EXTENT_WIDTH, EGO_EXTENT_HEIGHT))\n",
    "        selected_agent = None\n",
    "        agent_label_probabilities = None\n",
    "        agent_velocity = None\n",
    "    else:\n",
    "        # this will raise IndexError if the agent is not in the frame or under agent-threshold\n",
    "        # this is a strict error, we cannot recover from this situation\n",
    "        try:\n",
    "            agent = filter_agents_by_track_id(\n",
    "                filter_agents_by_labels(cur_agents, filter_agents_threshold), selected_track_id\n",
    "            )[0]\n",
    "        except IndexError:\n",
    "            raise ValueError(f\" track_id {selected_track_id} not in frame or below threshold\")\n",
    "        agent_centroid = agent[\"centroid\"]\n",
    "        agent_yaw = float(agent[\"yaw\"])\n",
    "        agent_extent = agent[\"extent\"]\n",
    "        selected_agent = agent\n",
    "        agent_label_probabilities = agent[\"label_probabilities\"]\n",
    "        agent_velocity = agent[\"velocity\"]\n",
    "\n",
    "    future_coords_offset, future_yaws_offset, future_availability, _ = _create_targets_for_deep_prediction(\n",
    "        future_num_frames, future_frames, selected_track_id, future_agents, agent_centroid[:2], agent_yaw,\n",
    "    )\n",
    "\n",
    "    # history_num_frames + 1 because it also includes the current frame\n",
    "    history_coords_offset, history_yaws_offset, history_availability, history_velocities = _create_targets_for_deep_prediction(\n",
    "        history_num_frames + 1, history_frames, selected_track_id, history_agents, agent_centroid[:2], agent_yaw,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"target_positions\": future_coords_offset,\n",
    "        \"target_yaws\": future_yaws_offset,\n",
    "        \"target_availabilities\": future_availability,\n",
    "        \"history_positions\": history_coords_offset,\n",
    "        \"history_yaws\": history_yaws_offset,\n",
    "        \"history_availabilities\": history_availability,\n",
    "        \"centroid\": agent_centroid,\n",
    "        \"yaw\": agent_yaw,\n",
    "        \"extent\": agent_extent,\n",
    "        \"label_probabilities\": agent_label_probabilities,\n",
    "        \"history_velocities\": history_velocities\n",
    "    }\n",
    "\n",
    "\n",
    "def _create_targets_for_deep_prediction(\n",
    "    num_frames: int,\n",
    "    frames: np.ndarray,\n",
    "    selected_track_id: Optional[int],\n",
    "    agents: List[np.ndarray],\n",
    "    agent_current_centroid: np.ndarray,\n",
    "    agent_current_yaw: float,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Internal function that creates the targets and availability masks for deep prediction-type models.\n",
    "    The futures/history offset (in meters) are computed. When no info is available (e.g. agent not in frame)\n",
    "    a 0 is set in the availability array (1 otherwise).\n",
    "    Args:\n",
    "        num_frames (int): number of offset we want in the future/history\n",
    "        frames (np.ndarray): available frames. This may be less than num_frames\n",
    "        selected_track_id (Optional[int]): agent track_id or AV (None)\n",
    "        agents (List[np.ndarray]): list of agents arrays (same len of frames)\n",
    "        agent_current_centroid (np.ndarray): centroid of the agent at timestep 0\n",
    "        agent_current_yaw (float): angle of the agent at timestep 0\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray]: position offsets, angle offsets, availabilities\n",
    "    \"\"\"\n",
    "    # How much the coordinates differ from the current state in meters.\n",
    "    coords_offset = np.zeros((num_frames, 2), dtype=np.float32)\n",
    "    velocities = np.zeros((num_frames, 2), dtype=np.float32)\n",
    "    yaws_offset = np.zeros((num_frames, 1), dtype=np.float32)\n",
    "    availability = np.zeros((num_frames,), dtype=np.float32)\n",
    "\n",
    "    for i, (frame, agents) in enumerate(zip(frames, agents)):\n",
    "        if selected_track_id is None:\n",
    "            agent_centroid = frame[\"ego_translation\"][:2]\n",
    "            agent_yaw = rotation33_as_yaw(frame[\"ego_rotation\"])\n",
    "            agent_velocity = None\n",
    "        else:\n",
    "            # it's not guaranteed the target will be in every frame\n",
    "            try:\n",
    "                agent = filter_agents_by_track_id(agents, selected_track_id)[0]\n",
    "            except IndexError:\n",
    "                availability[i] = 0.0  # keep track of invalid futures/history\n",
    "                continue\n",
    "\n",
    "            agent_centroid = agent[\"centroid\"]\n",
    "            agent_yaw = agent[\"yaw\"]\n",
    "            agent_velocity = agent[\"velocity\"]\n",
    "\n",
    "        coords_offset[i] = agent_centroid - agent_current_centroid\n",
    "        velocities[i] = agent_velocity\n",
    "        yaws_offset[i] = angular_distance(agent_yaw, agent_current_yaw)\n",
    "        availability[i] = 1.0\n",
    "    return coords_offset, yaws_offset, availability, velocities[:num_frames - 1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "from functools import partial\n",
    "from typing import Optional, Tuple, cast\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from l5kit.data import (\n",
    "    ChunkedDataset,\n",
    "    get_agents_slice_from_frames,\n",
    "    get_frames_slice_from_scenes,\n",
    "    get_tl_faces_slice_from_frames,\n",
    ")\n",
    "\n",
    "\n",
    "class EgoDatasetModified(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cfg: dict,\n",
    "        zarr_dataset: ChunkedDataset,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Get a PyTorch dataset object that can be used to train DNN\n",
    "        Args:\n",
    "            cfg (dict): configuration file\n",
    "            zarr_dataset (ChunkedDataset): the raw zarr dataset\n",
    "        \"\"\"\n",
    "        self.cfg = cfg\n",
    "        self.dataset = zarr_dataset\n",
    "\n",
    "        self.cumulative_sizes = self.dataset.scenes[\"frame_index_interval\"][:, 1]\n",
    "\n",
    "        # build a partial so we don't have to access cfg each time\n",
    "        self.sample_function = partial(\n",
    "            generate_agent_sample,\n",
    "            history_num_frames=cfg[\"model_params\"][\"history_num_frames\"],\n",
    "            history_step_size=cfg[\"model_params\"][\"history_step_size\"],\n",
    "            future_num_frames=cfg[\"model_params\"][\"future_num_frames\"],\n",
    "            future_step_size=cfg[\"model_params\"][\"future_step_size\"],\n",
    "            filter_agents_threshold=cfg[\"raster_params\"][\"filter_agents_threshold\"],\n",
    "            perturbation=None,\n",
    "        )\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Get the number of available AV frames\n",
    "        Returns:\n",
    "            int: the number of elements in the dataset\n",
    "        \"\"\"\n",
    "        return len(self.dataset.frames)\n",
    "\n",
    "    def get_frame(self, scene_index: int, state_index: int, track_id: Optional[int] = None) -> dict:\n",
    "        \"\"\"\n",
    "        A utility function to get the rasterisation and trajectory target for a given agent in a given frame\n",
    "        Args:\n",
    "            scene_index (int): the index of the scene in the zarr\n",
    "            state_index (int): a relative frame index in the scene\n",
    "            track_id (Optional[int]): the agent to rasterize or None for the AV\n",
    "        Returns:\n",
    "            dict: the rasterised image, the target trajectory (position and yaw) along with their availability,\n",
    "            the 2D matrix to center that agent, the agent track (-1 if ego) and the timestamp\n",
    "        \"\"\"\n",
    "        frames = self.dataset.frames[get_frames_slice_from_scenes(self.dataset.scenes[scene_index])]\n",
    "        data = self.sample_function(state_index, frames, self.dataset.agents, self.dataset.tl_faces, track_id)\n",
    "\n",
    "        target_positions = np.array(data[\"target_positions\"], dtype=np.float32)\n",
    "        target_yaws = np.array(data[\"target_yaws\"], dtype=np.float32)\n",
    "\n",
    "        history_positions = np.array(data[\"history_positions\"], dtype=np.float32)\n",
    "        history_velocities = np.array(data[\"history_velocities\"], dtype=np.float32)\n",
    "        history_yaws = np.array(data[\"history_yaws\"], dtype=np.float32)\n",
    "\n",
    "        timestamp = frames[state_index][\"timestamp\"]\n",
    "        track_id = np.int64(-1 if track_id is None else track_id)  # always a number to avoid crashing torch\n",
    "            \n",
    "        return {\n",
    "            \"target_positions\": target_positions,\n",
    "            \"target_yaws\": target_yaws,\n",
    "            \"target_availabilities\": data[\"target_availabilities\"],\n",
    "            \"history_positions\": history_positions,\n",
    "            \"history_yaws\": history_yaws,\n",
    "            \"history_availabilities\": data[\"history_availabilities\"],\n",
    "            \"track_id\": track_id,\n",
    "            \"timestamp\": timestamp,\n",
    "            \"centroid\": data[\"centroid\"],\n",
    "            \"yaw\": data[\"yaw\"],\n",
    "            \"extent\": data[\"extent\"],\n",
    "            \"label_probabilities\": data[\"label_probabilities\"],\n",
    "            \"history_velocities\": history_velocities,\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, index: int) -> dict:\n",
    "        \"\"\"\n",
    "        Function called by Torch to get an element\n",
    "        Args:\n",
    "            index (int): index of the element to retrieve\n",
    "        Returns: please look get_frame signature and docstring\n",
    "        \"\"\"\n",
    "        if index < 0:\n",
    "            if -index > len(self):\n",
    "                raise ValueError(\"absolute value of index should not exceed dataset length\")\n",
    "            index = len(self) + index\n",
    "\n",
    "        scene_index = bisect.bisect_right(self.cumulative_sizes, index)\n",
    "\n",
    "        if scene_index == 0:\n",
    "            state_index = index\n",
    "        else:\n",
    "            state_index = index - self.cumulative_sizes[scene_index - 1]\n",
    "        return self.get_frame(scene_index, state_index)\n",
    "\n",
    "    def get_scene_dataset(self, scene_index: int) -> \"EgoDataset\":\n",
    "        \"\"\"\n",
    "        Returns another EgoDataset dataset where the underlying data can be modified.\n",
    "        This is possible because, even if it supports the same interface, this dataset is np.ndarray based.\n",
    "        Args:\n",
    "            scene_index (int): the scene index of the new dataset\n",
    "        Returns:\n",
    "            EgoDataset: A valid EgoDataset dataset with a copy of the data\n",
    "        \"\"\"\n",
    "        # copy everything to avoid references (scene is already detached from zarr if get_combined_scene was called)\n",
    "        scenes = self.dataset.scenes[scene_index : scene_index + 1].copy()\n",
    "        frame_slice = get_frames_slice_from_scenes(*scenes)\n",
    "        frames = self.dataset.frames[frame_slice].copy()\n",
    "        agent_slice = get_agents_slice_from_frames(*frames[[0, -1]])\n",
    "        tl_slice = get_tl_faces_slice_from_frames(*frames[[0, -1]])\n",
    "\n",
    "        agents = self.dataset.agents[agent_slice].copy()\n",
    "        tl_faces = self.dataset.tl_faces[tl_slice].copy()\n",
    "\n",
    "        frames[\"agent_index_interval\"] -= agent_slice.start\n",
    "        frames[\"traffic_light_faces_index_interval\"] -= tl_slice.start\n",
    "        scenes[\"frame_index_interval\"] -= frame_slice.start\n",
    "\n",
    "        dataset = ChunkedDataset(\"\")\n",
    "        dataset.agents = agents\n",
    "        dataset.tl_faces = tl_faces\n",
    "        dataset.frames = frames\n",
    "        dataset.scenes = scenes\n",
    "\n",
    "        return EgoDataset(self.cfg, dataset)\n",
    "\n",
    "    def get_scene_indices(self, scene_idx: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get indices for the given scene. EgoDataset iterates over frames, so this is just a matter\n",
    "        of finding the scene boundaries.\n",
    "        Args:\n",
    "            scene_idx (int): index of the scene\n",
    "        Returns:\n",
    "            np.ndarray: indices that can be used for indexing with __getitem__\n",
    "        \"\"\"\n",
    "        scenes = self.dataset.scenes\n",
    "        assert scene_idx < len(scenes), f\"scene_idx {scene_idx} is over len {len(scenes)}\"\n",
    "        return np.arange(*scenes[scene_idx][\"frame_index_interval\"])\n",
    "\n",
    "    def get_frame_indices(self, frame_idx: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get indices for the given frame. EgoDataset iterates over frames, so this will be a single element\n",
    "        Args:\n",
    "            frame_idx (int): index of the scene\n",
    "        Returns:\n",
    "            np.ndarray: indices that can be used for indexing with __getitem__\n",
    "        \"\"\"\n",
    "        frames = self.dataset.frames\n",
    "        assert frame_idx < len(frames), f\"frame_idx {frame_idx} is over len {len(frames)}\"\n",
    "        return np.asarray((frame_idx,), dtype=np.int64)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return self.dataset.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "from zarr import convenience\n",
    "\n",
    "from l5kit.data import ChunkedDataset, get_agents_slice_from_frames, get_frames_slice_from_scenes\n",
    "from l5kit.dataset.select_agents import TH_DISTANCE_AV, TH_EXTENT_RATIO, TH_YAW_DEGREE, select_agents\n",
    "\n",
    "# WARNING: changing these values impact the number of instances selected for both train and inference!\n",
    "MIN_FRAME_HISTORY = 10  # minimum number of frames an agents must have in the past to be picked\n",
    "MIN_FRAME_FUTURE = 1  # minimum number of frames an agents must have in the future to be picked\n",
    "\n",
    "\n",
    "class AgentDatasetModified(EgoDatasetModified):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cfg: dict,\n",
    "        zarr_dataset: ChunkedDataset,\n",
    "        agents_mask: Optional[np.ndarray] = None,\n",
    "        min_frame_history: int = MIN_FRAME_HISTORY,\n",
    "        min_frame_future: int = MIN_FRAME_FUTURE,\n",
    "    ):\n",
    "\n",
    "        super(AgentDatasetModified, self).__init__(cfg, zarr_dataset)\n",
    "        if agents_mask is None:  # if not provided try to load it from the zarr\n",
    "            agents_mask = self.load_agents_mask()\n",
    "            past_mask = agents_mask[:, 0] >= min_frame_history\n",
    "            future_mask = agents_mask[:, 1] >= min_frame_future\n",
    "            agents_mask = past_mask * future_mask\n",
    "\n",
    "            if min_frame_history != MIN_FRAME_HISTORY:\n",
    "                print(f\"warning, you're running with custom min_frame_history of {min_frame_history}\")\n",
    "            if min_frame_future != MIN_FRAME_FUTURE:\n",
    "                print(f\"warning, you're running with custom min_frame_future of {min_frame_future}\")\n",
    "        else:\n",
    "            print(\"warning, you're running with a custom agents_mask\")\n",
    "\n",
    "        # store the valid agents indexes\n",
    "        self.agents_indices = np.nonzero(agents_mask)[0]\n",
    "        # this will be used to get the frame idx from the agent idx\n",
    "        self.cumulative_sizes_agents = self.dataset.frames[\"agent_index_interval\"][:, 1]\n",
    "        self.agents_mask = agents_mask\n",
    "\n",
    "    def load_agents_mask(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Loads a boolean mask of the agent availability stored into the zarr. Performs some sanity check against cfg.\n",
    "        Returns: a boolean mask of the same length of the dataset agents\n",
    "        \"\"\"\n",
    "        agent_prob = self.cfg[\"raster_params\"][\"filter_agents_threshold\"]\n",
    "\n",
    "        agents_mask_path = Path(self.dataset.path) / f\"agents_mask/{agent_prob}\"\n",
    "        if not agents_mask_path.exists():  # don't check in root but check for the path\n",
    "            print(\n",
    "                f\"cannot find the right config in {self.dataset.path},\\n\"\n",
    "                f\"your cfg has loaded filter_agents_threshold={agent_prob};\\n\"\n",
    "                \"but that value doesn't have a match among the agents_mask in the zarr\\n\"\n",
    "                \"Mask will now be generated for that parameter.\"\n",
    "            )\n",
    "            select_agents(\n",
    "                self.dataset,\n",
    "                agent_prob,\n",
    "                th_yaw_degree=TH_YAW_DEGREE,\n",
    "                th_extent_ratio=TH_EXTENT_RATIO,\n",
    "                th_distance_av=TH_DISTANCE_AV,\n",
    "            )\n",
    "\n",
    "        agents_mask = convenience.load(str(agents_mask_path))  # note (lberg): this doesn't update root\n",
    "        return agents_mask\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        length of the available and reliable agents (filtered using the mask)\n",
    "        Returns: the length of the dataset\n",
    "        \"\"\"\n",
    "        return len(self.agents_indices)\n",
    "\n",
    "    def __getitem__(self, index: int) -> dict:\n",
    "        \"\"\"\n",
    "        Differs from parent by iterating on agents and not AV.\n",
    "        \"\"\"\n",
    "        if index < 0:\n",
    "            if -index > len(self):\n",
    "                raise ValueError(\"absolute value of index should not exceed dataset length\")\n",
    "            index = len(self) + index\n",
    "\n",
    "        index = self.agents_indices[index]\n",
    "        track_id = self.dataset.agents[index][\"track_id\"]\n",
    "        frame_index = bisect.bisect_right(self.cumulative_sizes_agents, index)\n",
    "        scene_index = bisect.bisect_right(self.cumulative_sizes, frame_index)\n",
    "\n",
    "        if scene_index == 0:\n",
    "            state_index = frame_index\n",
    "        else:\n",
    "            state_index = frame_index - self.cumulative_sizes[scene_index - 1]\n",
    "        return self.get_frame(scene_index, state_index, track_id=track_id)\n",
    "\n",
    "    def get_scene_dataset(self, scene_index: int) -> \"AgentDatasetModified\":\n",
    "        \"\"\"\n",
    "        Differs from parent only in the return type.\n",
    "        Instead of doing everything from scratch, we rely on super call and fix the agents_mask\n",
    "        \"\"\"\n",
    "\n",
    "        new_dataset = super(AgentDatasetModified, self).get_scene_dataset(scene_index).dataset\n",
    "\n",
    "        # filter agents_bool values\n",
    "        frame_interval = self.dataset.scenes[scene_index][\"frame_index_interval\"]\n",
    "        # ASSUMPTION: all agents_index are consecutive\n",
    "        start_index = self.dataset.frames[frame_interval[0]][\"agent_index_interval\"][0]\n",
    "        end_index = self.dataset.frames[frame_interval[1] - 1][\"agent_index_interval\"][1]\n",
    "        agents_mask = self.agents_mask[start_index:end_index].copy()\n",
    "\n",
    "        return AgentDatasetModified(\n",
    "            self.cfg, new_dataset, agents_mask  # overwrite the loaded one\n",
    "        )\n",
    "\n",
    "    def get_scene_indices(self, scene_idx: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get indices for the given scene. Here __getitem__ iterate over valid agents indices.\n",
    "        This means ``__getitem__(0)`` matches the first valid agent in the dataset.\n",
    "        Args:\n",
    "            scene_idx (int): index of the scene\n",
    "        Returns:\n",
    "            np.ndarray: indices that can be used for indexing with __getitem__\n",
    "        \"\"\"\n",
    "        scenes = self.dataset.scenes\n",
    "        assert scene_idx < len(scenes), f\"scene_idx {scene_idx} is over len {len(scenes)}\"\n",
    "        frame_slice = get_frames_slice_from_scenes(scenes[scene_idx])\n",
    "        agent_slice = get_agents_slice_from_frames(*self.dataset.frames[frame_slice][[0, -1]])\n",
    "\n",
    "        mask_valid_indices = (self.agents_indices >= agent_slice.start) * (self.agents_indices < agent_slice.stop)\n",
    "        indices = np.nonzero(mask_valid_indices)[0]\n",
    "        return indices\n",
    "\n",
    "    def get_frame_indices(self, frame_idx: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get indices for the given frame. Here __getitem__ iterate over valid agents indices.\n",
    "        This means ``__getitem__(0)`` matches the first valid agent in the dataset.\n",
    "        Args:\n",
    "            frame_idx (int): index of the scene\n",
    "        Returns:\n",
    "            np.ndarray: indices that can be used for indexing with __getitem__\n",
    "        \"\"\"\n",
    "        frames = self.dataset.frames\n",
    "        assert frame_idx < len(frames), f\"frame_idx {frame_idx} is over len {len(frames)}\"\n",
    "\n",
    "        agent_slice = get_agents_slice_from_frames(frames[frame_idx])\n",
    "\n",
    "        mask_valid_indices = (self.agents_indices >= agent_slice.start) * (self.agents_indices < agent_slice.stop)\n",
    "        indices = np.nonzero(mask_valid_indices)[0]\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'format_version': 4,\n",
       " 'model_params': {'model_architecture': 'resnet50',\n",
       "  'history_num_frames': 10,\n",
       "  'history_step_size': 1,\n",
       "  'history_delta_time': 0.1,\n",
       "  'future_num_frames': 50,\n",
       "  'future_step_size': 1,\n",
       "  'future_delta_time': 0.1},\n",
       " 'raster_params': {'raster_size': [224, 224],\n",
       "  'pixel_size': [0.5, 0.5],\n",
       "  'ego_center': [0.25, 0.5],\n",
       "  'map_type': 'py_semantic',\n",
       "  'satellite_map_key': 'aerial_map/aerial_map.png',\n",
       "  'semantic_map_key': 'semantic_map/semantic_map.pb',\n",
       "  'dataset_meta_key': 'meta.json',\n",
       "  'filter_agents_threshold': 0.5},\n",
       " 'train_data_loader': {'key': 'scenes/sample.zarr',\n",
       "  'batch_size': 12,\n",
       "  'shuffle': True,\n",
       "  'num_workers': 16},\n",
       " 'val_data_loader': {'key': 'scenes/sample.zarr',\n",
       "  'batch_size': 12,\n",
       "  'shuffle': False,\n",
       "  'num_workers': 16},\n",
       " 'train_params': {'checkpoint_every_n_steps': 10000,\n",
       "  'max_num_steps': 5,\n",
       "  'eval_every_n_steps': 10000}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = {'format_version': 4, 'model_params': {'model_architecture': 'resnet50', 'history_num_frames': 10, 'history_step_size': 1, 'history_delta_time': 0.1, 'future_num_frames': 50, 'future_step_size': 1, 'future_delta_time': 0.1}, 'raster_params': {'raster_size': [224, 224], 'pixel_size': [0.5, 0.5], 'ego_center': [0.25, 0.5], 'map_type': 'py_semantic', 'satellite_map_key': 'aerial_map/aerial_map.png', 'semantic_map_key': 'semantic_map/semantic_map.pb', 'dataset_meta_key': 'meta.json', 'filter_agents_threshold': 0.5}, 'train_data_loader': {'key': 'scenes/sample.zarr', 'batch_size': 12, 'shuffle': True, 'num_workers': 16}, 'val_data_loader': {'key': 'scenes/sample.zarr', 'batch_size': 12, 'shuffle': False, 'num_workers': 16}, 'train_params': {'checkpoint_every_n_steps': 10000, 'max_num_steps': 5, 'eval_every_n_steps': 10000}}\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "import os\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = \"input/\"\n",
    "dm = LocalDataManager(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cfg = cfg[\"train_data_loader\"]\n",
    "train_zarr = ChunkedDataset(dm.require('scenes/train.zarr')).open()\n",
    "train_dataset = AgentDatasetModified(cfg, train_zarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22496709"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21624612"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_zarr = ChunkedDataset(dm.require('scenes/validate.zarr')).open()\n",
    "val_dataset = AgentDatasetModified(cfg, val_zarr)\n",
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191177863"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full_zarr = ChunkedDataset(dm.require('scenes/train_full.zarr')).open()\n",
    "train_full_dataset = AgentDatasetModified(cfg, train_full_zarr)\n",
    "len(train_full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=False, batch_size=1024, \n",
    "                             num_workers=30,\n",
    "                             collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9480c230e0da45b5b3342ff858a95d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21970.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-195:\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/raman/anaconda3/envs/trajectory/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fdf155bba70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/raman/anaconda3/envs/trajectory/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 962, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/raman/anaconda3/envs/trajectory/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 942, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/raman/anaconda3/envs/trajectory/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/raman/anaconda3/envs/trajectory/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/home/raman/anaconda3/envs/trajectory/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7f4a1a05ae42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabel_probs_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mlabel_probs_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_probabilities'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/raman/anaconda3/envs/trajectory/lib/python3.7/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/raman/anaconda3/envs/trajectory/lib/python3.7/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/raman/anaconda3/envs/trajectory/lib/python3.7/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/raman/anaconda3/envs/trajectory/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/raman/anaconda3/envs/trajectory/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/raman/anaconda3/envs/trajectory/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "label_probs_list = []\n",
    "for batch in tqdm(train_dataloader):    \n",
    "    label_probs_list.extend([x['label_probabilities'] for x in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_probs_all = np.vstack(label_probs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "label_probs_df = pd.DataFrame(label_probs_all, columns=[\n",
    "    \"PERCEPTION_LABEL_NOT_SET\",\n",
    "    \"PERCEPTION_LABEL_UNKNOWN\",\n",
    "    \"PERCEPTION_LABEL_DONTCARE\",\n",
    "    \"PERCEPTION_LABEL_CAR\",\n",
    "    \"PERCEPTION_LABEL_VAN\",\n",
    "    \"PERCEPTION_LABEL_TRAM\",\n",
    "    \"PERCEPTION_LABEL_BUS\",\n",
    "    \"PERCEPTION_LABEL_TRUCK\",\n",
    "    \"PERCEPTION_LABEL_EMERGENCY_VEHICLE\",\n",
    "    \"PERCEPTION_LABEL_OTHER_VEHICLE\",\n",
    "    \"PERCEPTION_LABEL_BICYCLE\",\n",
    "    \"PERCEPTION_LABEL_MOTORCYCLE\",\n",
    "    \"PERCEPTION_LABEL_CYCLIST\",\n",
    "    \"PERCEPTION_LABEL_MOTORCYCLIST\",\n",
    "    \"PERCEPTION_LABEL_PEDESTRIAN\",\n",
    "    \"PERCEPTION_LABEL_ANIMAL\",\n",
    "    \"AVRESEARCH_LABEL_DONTCARE\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PERCEPTION_LABEL_NOT_SET               True\n",
       "PERCEPTION_LABEL_UNKNOWN               True\n",
       "PERCEPTION_LABEL_DONTCARE              True\n",
       "PERCEPTION_LABEL_CAR                  False\n",
       "PERCEPTION_LABEL_VAN                   True\n",
       "PERCEPTION_LABEL_TRAM                  True\n",
       "PERCEPTION_LABEL_BUS                   True\n",
       "PERCEPTION_LABEL_TRUCK                 True\n",
       "PERCEPTION_LABEL_EMERGENCY_VEHICLE     True\n",
       "PERCEPTION_LABEL_OTHER_VEHICLE         True\n",
       "PERCEPTION_LABEL_BICYCLE               True\n",
       "PERCEPTION_LABEL_MOTORCYCLE            True\n",
       "PERCEPTION_LABEL_CYCLIST              False\n",
       "PERCEPTION_LABEL_MOTORCYCLIST          True\n",
       "PERCEPTION_LABEL_PEDESTRIAN           False\n",
       "PERCEPTION_LABEL_ANIMAL                True\n",
       "AVRESEARCH_LABEL_DONTCARE              True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_probs_df.apply(lambda x: np.sum(x == 0)/len(x) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raman/anaconda3/envs/trajectory/lib/python3.7/site-packages/seaborn/distributions.py:369: UserWarning: Default bandwidth for data is 0; skipping density estimation.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='PERCEPTION_LABEL_CAR'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(label_probs_df['PERCEPTION_LABEL_CAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raman/anaconda3/envs/trajectory/lib/python3.7/site-packages/seaborn/distributions.py:369: UserWarning: Default bandwidth for data is 0; skipping density estimation.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='PERCEPTION_LABEL_CYCLIST'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(label_probs_df['PERCEPTION_LABEL_CYCLIST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raman/anaconda3/envs/trajectory/lib/python3.7/site-packages/seaborn/distributions.py:369: UserWarning: Default bandwidth for data is 0; skipping density estimation.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='PERCEPTION_LABEL_PEDESTRIAN'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(label_probs_df['PERCEPTION_LABEL_PEDESTRIAN'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
