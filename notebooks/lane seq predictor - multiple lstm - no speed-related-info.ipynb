{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refs: https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation-batched.ipynb\n",
    "https://github.com/budzianowski/PyTorch-Beam-Search-Decoding/blob/master/decode_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b2c21f39e74b77a4eabca5aa772cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Computing lane adjacency lists', max=528.0, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71669f643f1b47bbacf6732aa3b06caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Computing lane adjacency lists', max=7977.0, style=Progre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6a9bb4395441848c2bd87b7c6f86d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Lane blocked sets..', layout=Layout(wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "import sys\n",
    "sys.path.insert(0, '../scripts')\n",
    "from map_traffic_lights_data import * #master_intersection_idx_2_tl_signal_indices, get_lane_point_coordinates, get_lane_len, lane_id_2_idx#get_lane_center_line\n",
    "# early stopping source: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "from pytorchtools import EarlyStopping\n",
    "from datetime import timedelta\n",
    "from typing import Dict, List\n",
    "import torch \n",
    "from torch.autograd import Variable\n",
    "from torch import Tensor\n",
    "from torch.nn import functional\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "import heapq\n",
    "from dataclasses import dataclass, field\n",
    "import time\n",
    "import gc\n",
    "from torchviz import make_dot\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_SEGMENT_I = 4\n",
    "# TRAIN_INPUT_PATHS = [f'../input/agent_lane_seq_df_validate_0.hdf5']#validate_0.hdf5']\n",
    "# VAL_INPUT_PATHS = [f'../input/agent_lane_seq_df_sample_0.hdf5']\n",
    "TRAIN_INPUT_PATHS = [f'../input/agent_lane_seq_df_validate_0_{MAP_SEGMENT_I}_preproc.hdf5']#validate_0.hdf5']\n",
    "VAL_INPUT_PATHS = [f'../input/agent_lane_seq_df_sample_0_{MAP_SEGMENT_I}_preproc.hdf5']\n",
    "VOCAB_PATH = f'../input/agent_lane_seq_df_validate_0_{MAP_SEGMENT_I}_preproc_vocab.pkl'\n",
    "HIST_LEN_FRAMES = 100\n",
    "FUTURE_LEN_FRAMES = 50\n",
    "MIN_REQUIRED_TOKEN_FREQ = 4\n",
    "AGENT_SPEED_MAX = 15.\n",
    "AGENT_YAW_MAX = 2*np.pi\n",
    "\n",
    "with open(os.path.join(SEGMENTS_OUTPUT_PATH, 'map_segment_2_lanes.pkl'), 'rb') as f:\n",
    "    map_segment_2_lanes = pickle.load(f)\n",
    "MAP_SEGMENT_2_X_MIN = [float('inf') for _ in range(len(map_segment_2_lanes))]\n",
    "MAP_SEGMENT_2_X_MAX = [-float('inf') for _ in range(len(map_segment_2_lanes))]\n",
    "MAP_SEGMENT_2_Y_MIN = [float('inf') for _ in range(len(map_segment_2_lanes))]\n",
    "MAP_SEGMENT_2_Y_MAX = [-float('inf') for _ in range(len(map_segment_2_lanes))]\n",
    "for map_segment in range(len(map_segment_2_lanes)):\n",
    "    for lane_id in map_segment_2_lanes[map_segment]:\n",
    "        lane_center = get_lane_center_line(lane_id)\n",
    "        x_min, x_max = lane_center[:, 0].min(), lane_center[:, 0].max()\n",
    "        y_min, y_max = lane_center[:, 1].min(), lane_center[:, 1].max()\n",
    "        if x_min < MAP_SEGMENT_2_X_MIN[map_segment]:\n",
    "            MAP_SEGMENT_2_X_MIN[map_segment] = x_min\n",
    "        if y_min < MAP_SEGMENT_2_Y_MIN[map_segment]:\n",
    "            MAP_SEGMENT_2_Y_MIN[map_segment] = y_min\n",
    "        if x_max > MAP_SEGMENT_2_X_MAX[map_segment]:\n",
    "            MAP_SEGMENT_2_X_MAX[map_segment] = x_max\n",
    "        if y_max > MAP_SEGMENT_2_Y_MAX[map_segment]:\n",
    "            MAP_SEGMENT_2_Y_MAX[map_segment] = y_max\n",
    "MAX_DIST_DIFF_M = 10\n",
    "\n",
    "trn_data_need_preprocessing = False\n",
    "val_data_need_preprocessing = False\n",
    "store_preprocessed_results = False\n",
    "\n",
    "trn_output_name = ''\n",
    "val_output_name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_lane_df_trn = pd.concat([pd.read_hdf(path, key='data') for path in TRAIN_INPUT_PATHS])\n",
    "# agent_lane_df_val = pd.concat([pd.read_hdf(path, key='data') for path in VAL_INPUT_PATHS])\n",
    "\n",
    "agent_lane_df_trn = pd.read_hdf(TRAIN_INPUT_PATHS[0], key='data')\n",
    "agent_lane_df_val = pd.read_hdf(VAL_INPUT_PATHS[0], key='data')\n",
    "\n",
    "\n",
    "def filter_map_segment(agent_lane_df, map_segment_i=MAP_SEGMENT_I):\n",
    "    agent_scene_2_last_map_segment = agent_lane_df.groupby(['agent_track_id', 'scene_idx'])['map_segment_group'].nth(-1)\n",
    "    map_segment_selection_ = agent_scene_2_last_map_segment[agent_scene_2_last_map_segment == map_segment_i].reset_index()\n",
    "    track_id__scene_idx__set = set((map_segment_selection_['agent_track_id'].map(lambda x: [x]) +\n",
    "                                    map_segment_selection_['scene_idx'].map(lambda x: [x])).map(tuple).values)\n",
    "    track_id__scene_idx__series = (agent_lane_df['agent_track_id'].map(lambda x: [x]) +\n",
    "                                   agent_lane_df['scene_idx'].map(lambda x: [x])).map(tuple)\n",
    "    agent_lane_df = agent_lane_df[track_id__scene_idx__series.map(lambda x: x in track_id__scene_idx__set)]\n",
    "    return agent_lane_df\n",
    "\n",
    "# def filter_map_segment(agent_lane_df, map_segment_i=MAP_SEGMENT_I):\n",
    "#     agent_lane_df = agent_lane_df[agent_lane_df['map_segment_group'] == map_segment_i]\n",
    "#     return agent_lane_df\n",
    "\n",
    "if trn_data_need_preprocessing:\n",
    "    agent_lane_df_trn = filter_map_segment(agent_lane_df_trn)[['lane_id', 'map_segment_group', 'lane_point_i', \n",
    "                            'agent_speed', 'agent_yaw', 'agent_centroid_shift', 'agent_track_id', 'scene_idx', 'timestamp']]\n",
    "\n",
    "if val_data_need_preprocessing:\n",
    "    agent_lane_df_val = filter_map_segment(agent_lane_df_val)[['lane_id', 'map_segment_group', 'lane_point_i',\n",
    "                        'agent_speed', 'agent_yaw', 'agent_centroid_shift', 'agent_track_id', 'scene_idx', 'timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 1000)\n",
    "# agent_lane_df_trn.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_ = (agent_lane_df_trn.loc[agent_lane_df_trn['the_same_agent_prev'], 'timestamp']\n",
    "#          .diff(1)\n",
    "#          .map(lambda x: x < timedelta(seconds=0.11))\n",
    "#          .value_counts())\n",
    "# temp_/temp_.sum()\n",
    "\n",
    "## True     0.984327\n",
    "## False    0.015673"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _temp = agent_lane_df_trn.groupby(['agent_track_id', 'scene_idx'])['map_segment_group'].nunique().value_counts()\n",
    "# _temp/_temp.sum()\n",
    "\n",
    "# # 1    0.967818\n",
    "# # 2    0.032179\n",
    "# # 3    0.000002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_valid_hist_seq_len(agent_lane_df):\n",
    "    valid_hist_len_list = []\n",
    "    is_the_same_agent_prev = agent_lane_df['the_same_agent_prev'].values\n",
    "    for row_i in tqdm(range(len(agent_lane_df)), desc='Last hist valid...'):\n",
    "        last_valid_idx = row_i\n",
    "        while (is_the_same_agent_prev[last_valid_idx] and\n",
    "               row_i - last_valid_idx + 1 < HIST_LEN_FRAMES):\n",
    "            last_valid_idx -= 1\n",
    "        valid_hist_len_list.append(row_i - last_valid_idx)\n",
    "    agent_lane_df['valid_hist_len'] = valid_hist_len_list \n",
    "     \n",
    "\n",
    "def compute_valid_future_seq_len(agent_lane_df):\n",
    "    is_the_same_agent_next = agent_lane_df['the_same_agent_next'].values\n",
    "    valid_future_len_list = []\n",
    "    for row_i in tqdm(range(len(agent_lane_df)), desc='Last future valid...'):\n",
    "        last_valid_idx = row_i + 1\n",
    "        if not is_the_same_agent_next[row_i]:\n",
    "            valid_future_len_list.append(0)\n",
    "            continue\n",
    "        while (last_valid_idx + 1 < len(is_the_same_agent_next) and\n",
    "               is_the_same_agent_next[last_valid_idx] and\n",
    "               last_valid_idx - row_i < FUTURE_LEN_FRAMES):\n",
    "            last_valid_idx += 1\n",
    "        valid_future_len_list.append(last_valid_idx - row_i)\n",
    "    agent_lane_df['valid_future_len'] = valid_future_len_list\n",
    "    \n",
    "if trn_data_need_preprocessing:\n",
    "    lanes_trn = agent_lane_df_trn['lane_id'].unique()\n",
    "    lane_2_count = agent_lane_df_trn.groupby(['lane_id'])['lane_id'].count()\n",
    "    infrequent_lane_points = set(lane_2_count[lane_2_count < MIN_REQUIRED_TOKEN_FREQ].index)\n",
    "    map_segment_2_train_vocab = defaultdict(dict)\n",
    "    map_segment_2_vocab_i_2_lane = defaultdict(list)\n",
    "\n",
    "    for lane_id in lanes_trn:\n",
    "        if lane_id not in infrequent_lane_points:\n",
    "            map_segment_2_train_vocab[MAP_SEGMENT_I][lane_id] = len(map_segment_2_train_vocab[MAP_SEGMENT_I])\n",
    "            map_segment_2_vocab_i_2_lane[MAP_SEGMENT_I].append(lane_id)\n",
    "    del infrequent_lane_points\n",
    "else:\n",
    "    with open(VOCAB_PATH, 'rb') as f:\n",
    "        map_segment_2_train_vocab = pickle.load(f)\n",
    "\n",
    "# mapping lane_point_id to vocab idx\n",
    "def compute_vocab_indices(agent_lane_df, map_segment_idx=MAP_SEGMENT_I):\n",
    "    def get_vocab_idx(lane_id):\n",
    "        if lane_id in map_segment_2_train_vocab[map_segment_idx]:\n",
    "            return map_segment_2_train_vocab[map_segment_idx][lane_id]\n",
    "        # unknown token\n",
    "        return len(map_segment_2_train_vocab[map_segment_idx])\n",
    "    agent_lane_df['lane_vocab_idx'] = agent_lane_df['lane_id'].map(lambda lane_id: get_vocab_idx(lane_id))\n",
    "                                                                              \n",
    "    \n",
    "# computing true agent coordinates\n",
    "def compute_agent_coord(agent_lane_df):\n",
    "    agent_lane_df['agent_coord'] = ((agent_lane_df['lane_id'].map(lambda x: [x]) +\n",
    "                                     agent_lane_df['lane_point_i'].map(lambda x: [x])).map(lambda x: get_lane_point_coordinates(*x)) +\n",
    "                                    agent_lane_df['agent_centroid_shift'])\n",
    "    \n",
    "    \n",
    "def get_dist_to_lane_end_in_sampled_points(lane_id, lane_point_idx):\n",
    "    lane_len_points = get_lane_len(lane_id)\n",
    "    return lane_len_points - lane_point_idx - 1\n",
    "\n",
    "\n",
    "def compute_agent_lane_features(agent_lane_df):\n",
    "    agent_lane_df['points_to_lane_end'] = (agent_lane_df['lane_id'].map(lambda x: [x]) +\n",
    "                                     agent_lane_df['lane_point_i'].map(lambda x: [x])).map(lambda x: get_dist_to_lane_end_in_sampled_points(*x))\n",
    "\n",
    "\n",
    "def estimate_agent_speed(agent_lane_df):\n",
    "    coord__coord_next__speed__is_the_same_series = (agent_lane_df['agent_coord'].map(lambda x: [x]) + \n",
    "                                                    agent_lane_df['agent_coord'].shift(-1).map(lambda x: [x]) + \n",
    "                                                    agent_lane_df['agent_speed'].map(lambda x: [x]) + \n",
    "                                                    agent_lane_df['the_same_agent_next'].map(lambda x: [x]))\n",
    "\n",
    "    def derive_speed_abs(coords, coords_next, speed, is_next_the_same):\n",
    "        if is_next_the_same:\n",
    "            coords_diff = coords_next - coords\n",
    "            return np.hypot(*coords_diff)*10\n",
    "        return speed\n",
    "    \n",
    "    agent_lane_df['agent_speed_derived'] = coord__coord_next__speed__is_the_same_series.map(lambda x: derive_speed_abs(*x))\n",
    "    \n",
    "\n",
    "def preprocess_agent_lane_df(agent_lane_df):\n",
    "#     agent_lane_df.sort_values(by=['scene_idx', 'agent_track_id', 'timestamp'], inplace=True)\n",
    "    agent_lane_df['the_same_agent_prev'] = ((agent_lane_df['agent_track_id'].shift(1) == agent_lane_df['agent_track_id']) & \n",
    "                                           (agent_lane_df['scene_idx'].shift(1) == agent_lane_df['scene_idx']) & \n",
    "                                           (agent_lane_df['timestamp'].diff(1) < timedelta(seconds=0.11))) # &\n",
    "#                                            (agent_lane_df['map_segment_group'].shift(1) == agent_lane_df['map_segment_group']))\n",
    "    agent_lane_df['the_same_agent_next'] = ((agent_lane_df['agent_track_id'].shift(-1) == agent_lane_df['agent_track_id']) & \n",
    "                                           (agent_lane_df['scene_idx'].shift(-1) == agent_lane_df['scene_idx']) & \n",
    "                                           (agent_lane_df['timestamp'].diff(1).shift(-1) < timedelta(seconds=0.11)))# &\n",
    "#                                            (agent_lane_df['map_segment_group'].shift(-1) == agent_lane_df['map_segment_group']))\n",
    "    \n",
    "    compute_valid_hist_seq_len(agent_lane_df)\n",
    "    compute_valid_future_seq_len(agent_lane_df)\n",
    "    compute_vocab_indices(agent_lane_df)\n",
    "    compute_agent_coord(agent_lane_df)\n",
    "    compute_agent_lane_features(agent_lane_df)\n",
    "#     estimate_agent_speed(agent_lane_df)\n",
    "    \n",
    "    \n",
    "def store_precomputed_df(agent_lane_df, input_paths, output_name, store_vocab=False):\n",
    "    if len(TRAIN_INPUT_PATHS) == 1:\n",
    "        output_path = os.path.splitext(input_paths[0])[0]+ f'_{MAP_SEGMENT_I}_preproc.hdf5'\n",
    "    elif output_name != '':\n",
    "        output_path = os.path.join('../input', f'{output_name}.hdf5')\n",
    "    else:\n",
    "        time_str = time.strftime('%Y%m%d_%H%M%S')\n",
    "        output_path = os.path.join('../input', f'_{\"_\".join([os.path.splitext(x)[0] for x in input_paths])}_{MAP_SEGMENT_I}_preprocessed_{time_str}.hdf5')\n",
    "    print('output_path', output_path)\n",
    "    agent_lane_df.to_hdf(output_path, key='data')\n",
    "    if store_vocab:\n",
    "        vocab_path = os.path.splitext(output_path)[0] + '_vocab.pkl'\n",
    "        with open(vocab_path, 'wb') as f:\n",
    "            pickle.dump(map_segment_2_train_vocab, f)\n",
    "                                   \n",
    "                                   \n",
    "if trn_data_need_preprocessing:\n",
    "    preprocess_agent_lane_df(agent_lane_df_trn)\n",
    "    if store_preprocessed_results:\n",
    "        store_precomputed_df(agent_lane_df_trn, TRAIN_INPUT_PATHS, trn_output_name, store_vocab=True)\n",
    "\n",
    "if val_data_need_preprocessing:\n",
    "    preprocess_agent_lane_df(agent_lane_df_val)\n",
    "    if store_preprocessed_results:\n",
    "        store_precomputed_df(agent_lane_df_val, VAL_INPUT_PATHS, val_output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_df = agent_lane_df_trn[(agent_lane_df_trn['agent_track_id'] == 18) & (agent_lane_df_trn['scene_idx'] == 7170)]\n",
    "# check_df['next_coord'] = check_df[['agent_coord', 'agent_yaw', 'agent_speed']].apply(lambda x: [x['agent_coord'][0] + np.cos(x['agent_yaw'])*x['agent_speed']/10,\n",
    "#                                                                         x['agent_coord'][1] + np.sin(x['agent_yaw'])*x['agent_speed']/10], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_lane_df_trn[(agent_lane_df_trn['agent_track_id'] == 18) & (agent_lane_df_trn['scene_idx'] == 7170)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 24.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_lane_df_trn['points_to_lane_end'].max(), agent_lane_df_trn['points_to_lane_end'].quantile(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "class LaneSeqModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab,\n",
    "                 embedding_dim=16,\n",
    "                 hidden_dim_lane_lstm=64,\n",
    "                 hidden_dim_speed_lstm=64,\n",
    "                 hidden_dim_coord_lstm=64,\n",
    "                 n_layers_lane_lstm=1,\n",
    "                 n_layers_speed_lstm=1,\n",
    "                 n_layers_coord_lstm=1,\n",
    "                 bidirectional_speed_lstm=False,\n",
    "                 map_segment=4,\n",
    "                 dropout=0.2,\n",
    "                 max_agent_points_to_lane_end=agent_lane_df_trn['points_to_lane_end'].max(),\n",
    "                 device='cuda:0',\n",
    "                 speed_max=AGENT_SPEED_MAX,\n",
    "                 yaw_max=AGENT_YAW_MAX,\n",
    "                 input_hist_max_len=HIST_LEN_FRAMES,\n",
    "                 prediction_horizon_steps=FUTURE_LEN_FRAMES,\n",
    "                 max_dist_diff_m=MAX_DIST_DIFF_M,\n",
    "                 agent_speed_max=AGENT_SPEED_MAX,\n",
    "                 agent_yaw_max=AGENT_YAW_MAX,\n",
    "                 beam_width=3):\n",
    "\n",
    "        self.device = device\n",
    "        self.vocab_size = len(vocab)\n",
    "\n",
    "        # Constructor\n",
    "        super().__init__()\n",
    "\n",
    "        # embedding layer\n",
    "        self.lane_embedding = nn.Embedding(self.vocab_size + 2,\n",
    "                                           embedding_dim)  # including PAD and UNKNOWN tokens, even though PAD must be redundant\n",
    "\n",
    "        # lstm for lanes seq\n",
    "        self.lstm_lanes = nn.LSTM(embedding_dim + 3,\n",
    "                            hidden_dim_lane_lstm,\n",
    "                            num_layers=n_layers_lane_lstm,\n",
    "                            bidirectional=False,\n",
    "                            dropout=dropout,\n",
    "                            batch_first=True)\n",
    "\n",
    "        # fc layer to estimate next lane probs\n",
    "        self.fc_next_lane_logits = nn.Linear(hidden_dim_lane_lstm, self.vocab_size + 2)\n",
    "        self.fc_next_lane_logits.bias.data.fill_(0.0)\n",
    "        # fc layer to estimate next dist to lane end\n",
    "        self.fc_next_dist_to_lane_end = nn.Linear(hidden_dim_lane_lstm, 1)\n",
    "        \n",
    "        # lane point coordinates\n",
    "        lane_point_coordinates = torch.zeros((self.vocab_size + 2, max_agent_points_to_lane_end, 2)).to(device)\n",
    "        for lane_id, vocab_i in vocab.items():\n",
    "            for points_to_lane_end in range(max_agent_points_to_lane_end):\n",
    "                lane_len = get_lane_len(lane_id)\n",
    "                lane_point_i = max(0, lane_len - 1 - points_to_lane_end)\n",
    "                point_coords = get_lane_point_coordinates(lane_id, lane_point_i)\n",
    "                lane_point_coordinates[vocab_i, points_to_lane_end, 0] = point_coords[0]\n",
    "                lane_point_coordinates[vocab_i, points_to_lane_end, 1] = point_coords[1]\n",
    "#         lane_point_coordinates_np = np.zeros((self.vocab_size + 2, max_agent_points_to_lane_end, 2))\n",
    "#         for lane_id, vocab_i in vocab.items():\n",
    "#             for points_to_lane_end in range(max_agent_points_to_lane_end):\n",
    "#                 lane_len = get_lane_len(lane_id)\n",
    "#                 lane_point_i = max(0, lane_len - 1 - points_to_lane_end)\n",
    "#                 lane_point_coordinates_np[vocab_i, points_to_lane_end] = get_lane_point_coordinates(lane_id, lane_point_i)\n",
    "#         lane_point_coordinates = Variable(torch.Tensor(lane_point_coordinates_np), requires_grad=False).to(device)\n",
    "        self.lane_point_x_coord = torch.squeeze(lane_point_coordinates[:, :, 0])\n",
    "        self.lane_point_y_coord = torch.squeeze(lane_point_coordinates[:, :, 1])\n",
    "\n",
    "        # lane_point probs activation\n",
    "        self.softmax_act = nn.Softmax(dim=-1)\n",
    "        \n",
    "        # lstm for speed/angle seq\n",
    "        self.lstm_speed = nn.LSTM(2,\n",
    "                            hidden_dim_speed_lstm,\n",
    "                            num_layers=n_layers_speed_lstm,\n",
    "                            bidirectional=bidirectional_speed_lstm,\n",
    "                            dropout=dropout,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        # fc layer to estimate next speed abs val\n",
    "        self.fc_next_speed_yaw = nn.Linear(hidden_dim_speed_lstm * (1 + int(bidirectional_speed_lstm)), 2)\n",
    "        self.bidirectional_speed_lstm = bidirectional_speed_lstm\n",
    "        \n",
    "        # lstm for true coord\n",
    "        self.lstm_coord = nn.LSTM(7,\n",
    "                            hidden_dim_coord_lstm,\n",
    "                            num_layers=n_layers_coord_lstm,\n",
    "                            bidirectional=False,\n",
    "                            dropout=dropout,\n",
    "                            batch_first=True)\n",
    "        \n",
    "#         # fc layer to enable model to ignore lane-based coord estimation (e.g. for cars far from lane)\n",
    "#         self.fc_is_lane_coord_relevant = nn.Linear(6, 1)\n",
    "#         self.fc_is_lane_coord_relevant.bias.data.fill_(-1)\n",
    "#         self.fc_is_const_accel_coord_relevant = nn.Linear(6, 1)\n",
    "#         self.fc_is_const_accel_coord_relevant.bias.data.fill_(0)\n",
    "#         self.fc_is_const_turn_coord_relevant = nn.Linear(6, 1)\n",
    "#         self.fc_is_const_turn_coord_relevant.bias.data.fill_(0)\n",
    "#         self.sigmoid_act = nn.Sigmoid()\n",
    "        \n",
    "        # fc to estimate offsets from fixed lane_point coordinates\n",
    "        # TODO: consider weight decay for combination of coord estimations: https://discuss.pytorch.org/t/simple-l2-regularization/139/2\n",
    "#         self.fc_coord = nn.Linear(hidden_dim_coord_lstm + hidden_dim_lane_lstm, 2)\n",
    "#         fc_head_num_features = (hidden_dim_coord_lstm + \n",
    "#                                 hidden_dim_lane_lstm + \n",
    "#                                 hidden_dim_speed_lstm * (1 + int(bidirectional_speed_lstm)))\n",
    "        fc_head_num_features = hidden_dim_coord_lstm\n",
    "        self.bn_1 = nn.BatchNorm1d(fc_head_num_features)\n",
    "        self.fc_coord_hidden = nn.Linear(fc_head_num_features, 32) # + \n",
    "#                                          hidden_dim_lane_lstm + \n",
    "#                                          hidden_dim_speed_lstm * (1 + int(bidirectional_speed_lstm)), 64)\n",
    "        self.fc_coord_hidden_act = nn.ReLU()\n",
    "        self.bn_2 = nn.BatchNorm1d(32)\n",
    "        self.fc_coord = nn.Linear(32, 2)\n",
    "#         self.fc_coord = nn.Linear(6 + \n",
    "#                                   hidden_dim_lane_lstm + \n",
    "#                                   hidden_dim_speed_lstm * (1 + int(bidirectional_speed_lstm)), 2)\n",
    "\n",
    "        self.prediction_horizon_steps = prediction_horizon_steps\n",
    "        self.input_hist_max_len = input_hist_max_len\n",
    "        \n",
    "        # normalization consts\n",
    "        self.max_dist_diff_m = max_dist_diff_m\n",
    "        self.x_coord_min = MAP_SEGMENT_2_X_MIN[map_segment]\n",
    "        self.x_coord_max = MAP_SEGMENT_2_X_MAX[map_segment]\n",
    "        self.y_coord_min = MAP_SEGMENT_2_Y_MIN[map_segment]\n",
    "        self.y_coord_max = MAP_SEGMENT_2_Y_MAX[map_segment]\n",
    "        self.fc_coord.bias.data = torch.Tensor([self.x_coord_min + (self.x_coord_max-self.x_coord_min)/2,\n",
    "                                                   self.y_coord_min + (self.y_coord_max-self.y_coord_min)/2])\n",
    "        self.speed_max = speed_max\n",
    "        self.yaw_max = yaw_max\n",
    "        self.max_agent_points_to_lane_end = max_agent_points_to_lane_end\n",
    "        self.agent_speed_max = agent_speed_max\n",
    "        self.agent_yaw_max = agent_yaw_max\n",
    "\n",
    "        # params for beam search\n",
    "        self.beam_width = beam_width\n",
    "        \n",
    "    def normalize_coordinates(self, coord_seq):\n",
    "        # coord seq shape = [batch_size, max_seq_len, 2]\n",
    "        max_min_range_x = (self.x_coord_max - self.x_coord_min)*torch.ones((coord_seq.shape[0], coord_seq.shape[1], 1))\n",
    "        max_min_range_y = (self.y_coord_max - self.y_coord_min)*torch.ones((coord_seq.shape[0], coord_seq.shape[1], 1))\n",
    "        max_min_range = torch.cat((max_min_range_x, max_min_range_y), dim=-1).to(self.device)\n",
    "        \n",
    "        min_x = self.x_coord_min*torch.ones((coord_seq.shape[0], coord_seq.shape[1], 1))\n",
    "        min_y = self.y_coord_min*torch.ones((coord_seq.shape[0], coord_seq.shape[1], 1))\n",
    "        min_vals = torch.cat((min_x, min_y), dim=-1).to(self.device)\n",
    "        \n",
    "        return (coord_seq - min_vals) / max_min_range\n",
    "    \n",
    "    def normalize_speed_yaw(self, speed_yaw_seq):\n",
    "        # coord seq shape = [batch_size, max_seq_len, 2]\n",
    "        max_speed_tensor = self.speed_max * torch.ones((speed_yaw_seq.shape[0], speed_yaw_seq.shape[1], 1))\n",
    "        max_yaw_tensor = self.yaw_max * torch.ones((speed_yaw_seq.shape[0], speed_yaw_seq.shape[1], 1))\n",
    "        max_vals_tensor = torch.cat((max_speed_tensor, max_yaw_tensor), dim=-1).to(self.device)\n",
    "        return speed_yaw_seq / max_vals_tensor\n",
    "    \n",
    "#     def mask_unreliable_coord_estimates():\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, lanes_seq, points_to_lane_end_seq, speed_seq, yaw_seq, coord_seq, seq_lengths, \n",
    "                beam=False, return_prediction_on_input=False, use_coord_selfpredictions=False):\n",
    "        # inputs are normalized in the dataset getter, except for coord_seq\n",
    "        \n",
    "        ############## lane seq ################\n",
    "        # lane_points_seq shape: [batch size, max_lane_seq_len]\n",
    "        lane_embedded = self.lane_embedding(lanes_seq)\n",
    "        # lane_embedded shape: [batch size, max_lane_seq_len, emb dim]\n",
    "\n",
    "        # adding centroid_shift_seq, speed_seq, yaw_seq\n",
    "        speed_yaw_input_batch = self.normalize_speed_yaw(torch.cat((torch.unsqueeze(speed_seq, 2),\n",
    "                                                                    torch.unsqueeze(yaw_seq, 2)), dim=2))\n",
    "        lanes_input_batch = torch.cat((lane_embedded,\n",
    "                                       torch.unsqueeze(points_to_lane_end_seq, 2)/self.max_agent_points_to_lane_end,\n",
    "                                       speed_yaw_input_batch), dim=2)\n",
    "        # packed sequence\n",
    "        packed_embedded_lanes_input_seq = nn.utils.rnn.pack_padded_sequence(lanes_input_batch, \n",
    "                                                                            seq_lengths, batch_first=True,\n",
    "                                                                            enforce_sorted=False)\n",
    "\n",
    "        lstm_output_lanes_, (hidden_lanes, cell_lanes) = self.lstm_lanes(packed_embedded_lanes_input_seq)\n",
    "        # hidden shape = [num layers, batch size, lanes hid dim]\n",
    "        # output shape = [seq_len, batch size, lanes hid dim]\n",
    "        \n",
    "        \n",
    "        lstm_output_lanes, _ = nn.utils.rnn.pad_packed_sequence(lstm_output_lanes_, \n",
    "                                                         batch_first=True, \n",
    "                                                         total_length=lanes_input_batch.shape[1])\n",
    "        # predictions of next lane and dist to lane end (in sampled points count) are trained with teacher on input seq\n",
    "        input_pred_next_lane = self.softmax_act(self.fc_next_lane_logits(lstm_output_lanes))\n",
    "        # input_pred_next_lane shape = [batch size, vocab size (all lanes + unknown&pad)]\n",
    "        input_pred_next_dist_to_lane_end = self.fc_next_dist_to_lane_end(lstm_output_lanes)\n",
    "        \n",
    "        ############## speed seq ################\n",
    "        # packed sequence\n",
    "        packed_embedded_speed_input_seq = nn.utils.rnn.pack_padded_sequence(speed_yaw_input_batch, \n",
    "                                                                            seq_lengths, batch_first=True,\n",
    "                                                                            enforce_sorted=False)\n",
    "        lstm_output_speed_, (hidden_speed, cell_speed) = self.lstm_speed(packed_embedded_speed_input_seq)\n",
    "        # predictions on input seq (with teacher)\n",
    "        lstm_output_speed, _ = nn.utils.rnn.pad_packed_sequence(lstm_output_speed_, \n",
    "                                                             batch_first=True, \n",
    "                                                             total_length=lanes_input_batch.shape[1])\n",
    "        input_pred_next_speed_yaw = self.fc_next_speed_yaw(lstm_output_speed)\n",
    "        \n",
    "        ############## coord seq ################\n",
    "        def combine_coord_estimates(coord_current, pred_next_speed_yaw, \n",
    "                                    pred_next_lane, pred_next_dist_to_lane_end,\n",
    "                                    speed_yaw_current, small_angle_threshold=0.04\n",
    "                                   ):\n",
    "            # estimating delta_x, delta_y based on assumption of constant x/y acceleration\n",
    "            # with teacher for input\n",
    "            \n",
    "            delta_x = (speed_yaw_current[:, :, 0]*torch.cos(speed_yaw_current[:, :, 1]) + \n",
    "                       pred_next_speed_yaw[:, :, 0]*torch.cos(pred_next_speed_yaw[:, :, 1]))/20\n",
    "            delta_y = (speed_yaw_current[:, :, 0]*torch.sin(speed_yaw_current[:, :, 1]) + \n",
    "                       pred_next_speed_yaw[:, :, 0]*torch.sin(pred_next_speed_yaw[:, :, 1]))/20\n",
    "            coord_estimation_const_accel = coord_current + torch.cat((torch.unsqueeze(delta_x, 2),\n",
    "                                                                      torch.unsqueeze(delta_y, 2)), dim=2)\n",
    "            \n",
    "\n",
    "            point_x_coord_weighted = torch.matmul(pred_next_lane, self.lane_point_x_coord)\n",
    "            point_y_coord_weighted = torch.matmul(pred_next_lane, self.lane_point_y_coord)\n",
    "            \n",
    "            pred_next_dist_to_lane_end_ceil = torch.clamp(torch.ceil(pred_next_dist_to_lane_end).long(), 0, self.max_agent_points_to_lane_end - 1)\n",
    "            pred_next_dist_to_lane_end_floor = torch.clamp(torch.floor(pred_next_dist_to_lane_end).long(), 0, self.max_agent_points_to_lane_end - 1)\n",
    "            pred_next_dist_to_lane_end_diff_to_ceil = pred_next_dist_to_lane_end - pred_next_dist_to_lane_end_ceil\n",
    "\n",
    "            \n",
    "            x_coord_weighted_ceil = torch.gather(point_x_coord_weighted, \n",
    "                                                 dim=2, \n",
    "                                                 index=pred_next_dist_to_lane_end_ceil)\n",
    "            x_coord_weighted_floor = torch.gather(point_x_coord_weighted, \n",
    "                                                 dim=2, \n",
    "                                                 index=pred_next_dist_to_lane_end_floor)\n",
    "            y_coord_weighted_ceil = torch.gather(point_y_coord_weighted, \n",
    "                                                 dim=2, \n",
    "                                                 index=pred_next_dist_to_lane_end_ceil)\n",
    "            y_coord_weighted_floor = torch.gather(point_y_coord_weighted, \n",
    "                                                 dim=2, \n",
    "                                                 index=pred_next_dist_to_lane_end_floor)\n",
    "            x_coord_weighted = (x_coord_weighted_ceil * (1 - pred_next_dist_to_lane_end_diff_to_ceil) + \n",
    "                                x_coord_weighted_floor * pred_next_dist_to_lane_end_diff_to_ceil)\n",
    "            y_coord_weighted = (y_coord_weighted_ceil * (1 - pred_next_dist_to_lane_end_diff_to_ceil) + \n",
    "                                y_coord_weighted_floor * pred_next_dist_to_lane_end_diff_to_ceil)\n",
    "            \n",
    "            coord_estimation_lane_pred = torch.cat((x_coord_weighted, \n",
    "                                                    y_coord_weighted), dim=-1)\n",
    "            \n",
    "#             if coord_current.shape[1] == 1:\n",
    "#                 print('coord_estimation_lane_pred', coord_estimation_lane_pred[0], \n",
    "#                       'coord_current', coord_current[0], 'delta_x', delta_x[0], 'delta_y', delta_y[0], \n",
    "#                       'speed x', speed_yaw_current[0, :, 0], 'yaw cos', torch.cos(speed_yaw_current[0, :, 1]))\n",
    "            \n",
    "\n",
    "            # estimating coord based on a single circle segment assumption\n",
    "            delta_alpha = pred_next_speed_yaw[:, :, 1] - speed_yaw_current[:, :, 1]\n",
    "            r = (speed_yaw_current[:, :, 0] + pred_next_speed_yaw[:, :, 0]) / (20*delta_alpha)\n",
    "            delta_x_turn = r * torch.cos(delta_alpha)\n",
    "            delta_y_turn = r * torch.sin(delta_alpha)\n",
    "            coord_estimation_const_turn = coord_current + torch.cat((torch.unsqueeze(delta_x_turn, 2),\n",
    "                                                                     torch.unsqueeze(delta_y_turn, 2)), dim=2)\n",
    "            \n",
    "            min_x = self.x_coord_min*torch.ones((coord_estimation_const_turn.shape[0], coord_estimation_const_turn.shape[1], 1))\n",
    "            min_y = self.y_coord_min*torch.ones((coord_estimation_const_turn.shape[0], coord_estimation_const_turn.shape[1], 1))\n",
    "            min_vals = torch.cat((min_x, min_y), dim=-1).to(self.device)\n",
    "            no_turn_datapoints_bool = (delta_alpha < small_angle_threshold).unsqueeze(dim=-1).repeat(1, 1, 2)\n",
    "            coord_estimation_const_turn = torch.where(no_turn_datapoints_bool, \n",
    "                                                      min_vals,\n",
    "                                                      coord_estimation_const_turn\n",
    "                                                     )\n",
    "            const_turn_estimations_present = (delta_alpha >= small_angle_threshold).unsqueeze(dim=-1).float()\n",
    "            coord_estimation_input_batch = torch.cat((self.normalize_coordinates(coord_estimation_const_accel),\n",
    "                                                      self.normalize_coordinates(coord_estimation_lane_pred),\n",
    "                                                      self.normalize_coordinates(coord_estimation_const_turn),\n",
    "                                                      const_turn_estimations_present\n",
    "                                                     ), dim=-1)\n",
    "            \n",
    "            coord_estimation_from_speed = (coord_estimation_const_accel + torch.where(no_turn_datapoints_bool, \n",
    "                                                                                      torch.zeros_like(coord_estimation_const_turn),\n",
    "                                                                                      coord_estimation_const_turn\n",
    "                                                     ))/(torch.ones_like(coord_estimation_const_accel) + const_turn_estimations_present)\n",
    "#             print('coord_estimation_input_batch', coord_estimation_input_batch[0])\n",
    "#             print('coord_estimation_const_accel', torch.sum(torch.isnan(coord_estimation_const_accel)), torch.sum(torch.isinf(coord_estimation_const_accel)), \n",
    "#                   'coord_estimation_const_turn', torch.sum(torch.isnan(coord_estimation_const_turn)), torch.sum(torch.isinf(coord_estimation_const_turn)), \n",
    "#                   'coord_estimation_input_batch', torch.sum(torch.isnan(coord_estimation_input_batch)), torch.sum(torch.isinf(coord_estimation_input_batch)))\n",
    "            \n",
    "            # storing differences between lane-based estimation and vector-speed approaches\n",
    "#             print(coord_estimation_const_accel)\n",
    "#             print('-'*5)\n",
    "#             print(coord_estimation_lane_pred)\n",
    "#             print('='*20)\n",
    "#             if len(coord_current.shape) == 3:\n",
    "#                 print(torch.sqrt(torch.square(coord_current - coord_estimation_const_accel)).mean())\n",
    "#                 print(torch.sum(torch.logical_not(no_turn_datapoints_bool)))\n",
    "#                 print(torch.sqrt(torch.square(coord_current[torch.logical_not(no_turn_datapoints_bool)] - \n",
    "#                                               coord_estimation_const_turn[torch.logical_not(no_turn_datapoints_bool)])).mean())\n",
    "#             lane_based_coord_diff_to_const_accel = torch.sqrt(torch.square(coord_estimation_lane_pred - coord_estimation_const_accel))\n",
    "#             lane_based_coord_diff_to_const_turn = torch.sqrt(torch.square(coord_estimation_lane_pred - coord_estimation_const_turn))\n",
    "#             const_accel_coord_diff_to_const_turn = torch.sqrt(torch.square(coord_estimation_const_accel - coord_estimation_const_turn))\n",
    "#             coord_estimation_discrepancies = torch.cat((lane_based_coord_diff_to_const_accel,\n",
    "#                                                       lane_based_coord_diff_to_const_turn,\n",
    "#                                                       const_accel_coord_diff_to_const_turn), dim=-1)/self.max_dist_diff_m\n",
    "            \n",
    "            return coord_estimation_input_batch, coord_estimation_lane_pred, coord_estimation_from_speed #torch.cat((coord_estimation_input_batch, coord_estimation_discrepancies), dim=-1)\n",
    "        \n",
    "        coord_estimation_input_batch, input_coord_estimation_lane_pred, input_coord_estimation_from_speed = combine_coord_estimates(coord_seq, input_pred_next_speed_yaw, \n",
    "                                                                               input_pred_next_lane, \n",
    "                                                                               input_pred_next_dist_to_lane_end, \n",
    "                                                                               speed_yaw_input_batch)\n",
    "        \n",
    "        packed_embedded_coord_estimation_input_seq = nn.utils.rnn.pack_padded_sequence(coord_estimation_input_batch, \n",
    "                                                                                       seq_lengths, batch_first=True,\n",
    "                                                                                       enforce_sorted=False)\n",
    "        lstm_output_coord_, (hidden_coord, cell_coord) = self.lstm_coord(packed_embedded_coord_estimation_input_seq)\n",
    "        def predict_coord(coord_estimation_input):\n",
    "            permute_for_bn = len(coord_estimation_input.shape) == 3\n",
    "            if permute_for_bn:\n",
    "                x = self.bn_1(coord_estimation_input.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "            else:\n",
    "                x = self.bn_1(coord_estimation_input)\n",
    "            x = self.fc_coord_hidden_act(self.fc_coord_hidden(x))\n",
    "            if permute_for_bn:\n",
    "                x = self.bn_2(x.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "            else:\n",
    "                x = self.bn_2(x)\n",
    "            return self.fc_coord(x)\n",
    "        \n",
    "        if return_prediction_on_input:\n",
    "            # predictions with teacher on input seq\n",
    "            lstm_output_coord, _ = nn.utils.rnn.pad_packed_sequence(lstm_output_coord_, \n",
    "                                                                 batch_first=True, \n",
    "                                                                 total_length=lanes_input_batch.shape[1])\n",
    "#             input_pred_next_coord = self.fc_coord(torch.cat((lstm_output_coord, lstm_output_lanes), dim=-1))\n",
    "#             print('final input', torch.cat((coord_estimation_input_batch, \n",
    "#                                                              lstm_output_lanes,\n",
    "#                                                              lstm_output_speed\n",
    "#                                                             ), dim=-1)[0])\n",
    "#             input_pred_next_coord = self.fc_coord(self.fc_coord_hidden(torch.cat((coord_estimation_input_batch, \n",
    "#                                                              lstm_output_lanes,\n",
    "#                                                              lstm_output_speed\n",
    "#                                                             ), dim=-1)))\n",
    "\n",
    "            \n",
    "            input_pred_next_coord = predict_coord(lstm_output_coord)\n",
    "                \n",
    "#             input_pred_next_coord = predict_coord(torch.cat((lstm_output_coord, \n",
    "#                                                              lstm_output_lanes,\n",
    "#                                                              lstm_output_speed\n",
    "#                                                             ), dim=-1)) # coord_estimation_input_batch)\n",
    "        \n",
    "        ############## storing last vals for consequent pred ##############\n",
    "        speed_yaw_current = torch.gather(speed_yaw_input_batch,\n",
    "                                      dim=1,\n",
    "                                      index=seq_lengths.unsqueeze(dim=-1).unsqueeze(dim=-1).repeat(1, 1, 2) - 1)\n",
    "        coord_current = torch.gather(coord_seq,\n",
    "                                  dim=1,\n",
    "                                  index=seq_lengths.unsqueeze(dim=-1).unsqueeze(dim=-1).repeat(1, 1, 2) - 1)\n",
    "        \n",
    "        coord_estimation_from_speed_current = torch.gather(input_coord_estimation_from_speed,\n",
    "                                  dim=1,\n",
    "                                  index=seq_lengths.unsqueeze(dim=-1).unsqueeze(dim=-1).repeat(1, 1, 2) - 1)\n",
    "#         print('coord_estimation_from_speed_current', coord_estimation_from_speed_current, 'coord_current', coord_current)\n",
    "        \n",
    "#         print('nans coord_current before loop', torch.sum(torch.isnan(coord_current)))\n",
    "        \n",
    "        coord_estimation_lane_pred = torch.gather(input_coord_estimation_lane_pred,\n",
    "                                  dim=1,\n",
    "                                  index=seq_lengths.unsqueeze(dim=-1).unsqueeze(dim=-1).repeat(1, 1, 2) - 1)\n",
    "        coord_estimation_from_speed = torch.gather(input_coord_estimation_from_speed,\n",
    "                                  dim=1,\n",
    "                                  index=seq_lengths.unsqueeze(dim=-1).unsqueeze(dim=-1).repeat(1, 1, 2) - 1)\n",
    "        coord_estimation_input = torch.gather(coord_estimation_input_batch,\n",
    "                                  dim=1,\n",
    "                                  index=seq_lengths.unsqueeze(dim=-1).unsqueeze(dim=-1).repeat(1, 1, \n",
    "                                                                                               coord_estimation_input_batch.shape[-1]) - 1)\n",
    "        \n",
    "        ############## future predictions ################\n",
    "        batch_size = lanes_seq.size(0)\n",
    "        pred_lane_prob = torch.zeros((batch_size, self.prediction_horizon_steps, self.vocab_size + 2)).to(\n",
    "            device)\n",
    "        pred_points_to_lane_end_seq = torch.zeros((batch_size, self.prediction_horizon_steps)).to(\n",
    "            device)\n",
    "        pred_speed = torch.zeros((batch_size, self.prediction_horizon_steps)).to(device)\n",
    "        pred_yaw = torch.zeros((batch_size, self.prediction_horizon_steps)).to(device)\n",
    "        pred_coordinates = torch.zeros((batch_size, self.prediction_horizon_steps, 2)).to(\n",
    "            device)\n",
    "        pred_coordinates_from_lanes = torch.zeros((batch_size, self.prediction_horizon_steps, 2)).to(\n",
    "            device)\n",
    "        pred_coordinates_from_speed = torch.zeros((batch_size, self.prediction_horizon_steps, 2)).to(\n",
    "            device)\n",
    "\n",
    "        for prediction_step in range(self.prediction_horizon_steps):            \n",
    "            ############## lane seq ################\n",
    "            hidden_lanes_last = hidden_lanes[-1, :, :]\n",
    "            pred_next_lane = self.softmax_act(self.fc_next_lane_logits(hidden_lanes_last))\n",
    "            pred_next_dist_to_lane_end = self.fc_next_dist_to_lane_end(hidden_lanes_last)\n",
    "            \n",
    "            ############## speed seq ################\n",
    "            if self.bidirectional_speed_lstm:\n",
    "                hidden_speed_last = torch.cat((hidden_speed[-2,:,:], hidden_speed[-1,:,:]), dim = 1) \n",
    "            else:\n",
    "                hidden_speed_last = hidden_speed[-1,:,:]\n",
    "            pred_next_speed_yaw = self.fc_next_speed_yaw(hidden_speed_last)\n",
    "            \n",
    "            ############## coord seq ################\n",
    "            hidden_coord_last = hidden_coord[-1, :, :]\n",
    "#             pred_next_coord = self.fc_coord(torch.cat((hidden_coord_last, hidden_lanes_last), dim=-1))\n",
    "#             print(coord_estimation.shape, hidden_lanes_last.shape, hidden_speed_last.shape)\n",
    "#             pred_next_coord = predict_coord(torch.cat((hidden_coord_last, \n",
    "#                                                        hidden_lanes_last,\n",
    "#                                                        hidden_speed_last\n",
    "#                                                             ), dim=-1)) #coord_estimation_input)\n",
    "            pred_next_coord = predict_coord(hidden_coord_last)\n",
    "            \n",
    "            \n",
    "\n",
    "#             pred_next_coord = self.fc_coord(self.fc_coord_hidden(torch.cat((coord_estimation, hidden_lanes_last, hidden_speed_last), dim=-1)))\n",
    "\n",
    "            \n",
    "            ###################################################\n",
    "            ############## storing predictions ################\n",
    "            pred_lane_prob[:, prediction_step, :] = pred_next_lane\n",
    "            pred_points_to_lane_end_seq[:, prediction_step:prediction_step + 1] = pred_next_dist_to_lane_end\n",
    "            pred_speed[:, prediction_step] = pred_next_speed_yaw[:, 0]\n",
    "            pred_yaw[:, prediction_step] = pred_next_speed_yaw[:, 1]\n",
    "            pred_coordinates[:, prediction_step, :] = torch.squeeze(pred_next_coord) \n",
    "            pred_coordinates_from_lanes[:, prediction_step, :] = torch.squeeze(coord_estimation_lane_pred)\n",
    "            pred_coordinates_from_speed[:, prediction_step, :] = torch.squeeze(coord_estimation_from_speed)\n",
    "            \n",
    "            ##########################################\n",
    "            ########## next lstm step ################\n",
    "            \n",
    "            # lane lstm\n",
    "            pred_next_lane = torch.unsqueeze(pred_next_lane, dim=1)\n",
    "            lanes_pred = torch.argmax(pred_next_lane, dim=-1)\n",
    "            embedded_lanes_pred = self.lane_embedding(lanes_pred)\n",
    "            pred_next_speed_yaw = torch.unsqueeze(pred_next_speed_yaw, dim=1)\n",
    "            pred_next_speed_yaw_scaled = self.normalize_speed_yaw(pred_next_speed_yaw)\n",
    "            pred_next_dist_to_lane_end = torch.unsqueeze(pred_next_dist_to_lane_end, dim=1)\n",
    "            lanes_lstm_input = torch.cat((embedded_lanes_pred,\n",
    "                                          pred_next_dist_to_lane_end/self.max_agent_points_to_lane_end,\n",
    "                                          pred_next_speed_yaw_scaled), dim=2)\n",
    "            _, (hidden_lanes, cell_lanes) = self.lstm_lanes(lanes_lstm_input, \n",
    "                                                            (hidden_lanes, cell_lanes))\n",
    "            \n",
    "            # speed lstm\n",
    "            _, (hidden_speed, cell_speed) = self.lstm_speed(pred_next_speed_yaw_scaled, \n",
    "                                                            (hidden_speed, cell_speed))\n",
    "            \n",
    "            # coord lstm\n",
    "            (coord_estimation_input, \n",
    "             coord_estimation_lane_pred, \n",
    "             coord_estimation_from_speed) = combine_coord_estimates(coord_current if use_coord_selfpredictions else coord_estimation_from_speed_current, \n",
    "                                                                    pred_next_speed_yaw,\n",
    "                                                       pred_next_lane, pred_next_dist_to_lane_end,\n",
    "                                                       speed_yaw_current)\n",
    "            _, (hidden_coord, cell_coord) = self.lstm_coord(coord_estimation_input, \n",
    "                                                            (hidden_coord, cell_coord))\n",
    "            \n",
    "            # storing last vals for the next lstm step\n",
    "            coord_current = torch.unsqueeze(pred_next_coord, dim=1)\n",
    "            coord_estimation_from_speed_current = coord_estimation_from_speed\n",
    "            speed_yaw_current = pred_next_speed_yaw\n",
    "\n",
    "        if return_prediction_on_input:\n",
    "            return (input_pred_next_lane, input_pred_next_dist_to_lane_end, input_pred_next_speed_yaw, \n",
    "                    input_pred_next_coord, input_coord_estimation_lane_pred, input_coord_estimation_from_speed,\n",
    "                    pred_lane_prob, pred_points_to_lane_end_seq, pred_speed, pred_yaw, \n",
    "                    pred_coordinates, pred_coordinates_from_lanes, pred_coordinates_from_speed)\n",
    "        return pred_lane_prob, pred_points_to_lane_end_seq, pred_speed, pred_yaw, pred_coordinates, pred_coordinates_from_lanes, pred_coordinates_from_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_seq_model = LaneSeqModel(map_segment_2_train_vocab[MAP_SEGMENT_I])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaneSeqModel(\n",
      "  (lane_embedding): Embedding(259, 16)\n",
      "  (lstm_lanes): LSTM(19, 64, batch_first=True, dropout=0.2)\n",
      "  (fc_next_lane_logits): Linear(in_features=64, out_features=259, bias=True)\n",
      "  (fc_next_dist_to_lane_end): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (softmax_act): Softmax(dim=-1)\n",
      "  (lstm_speed): LSTM(2, 64, batch_first=True, dropout=0.2)\n",
      "  (fc_next_speed_yaw): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (lstm_coord): LSTM(7, 64, batch_first=True, dropout=0.2)\n",
      "  (bn_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc_coord_hidden): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc_coord_hidden_act): ReLU()\n",
      "  (bn_2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc_coord): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(lane_seq_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaneSeqDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 agent_lane_df: pd.DataFrame,\n",
    "                 valid_indices: np.array,\n",
    "                 train_vocab_size: int,\n",
    "                 history_len: int = HIST_LEN_FRAMES,\n",
    "                 future_len: int = FUTURE_LEN_FRAMES\n",
    "                ):\n",
    "        self.history_len = history_len\n",
    "        self.future_len = future_len\n",
    "        self.valid_indices = valid_indices\n",
    "        self.PAD_TOKEN_IDX = train_vocab_size + 1\n",
    "        self.valid_hist_len = agent_lane_df['valid_hist_len'].values\n",
    "        self.valid_future_len = agent_lane_df['valid_future_len'].values\n",
    "        self.lane_vocab_idx = agent_lane_df['lane_vocab_idx'].values\n",
    "        self.agent_speed = agent_lane_df['agent_speed'].values\n",
    "        self.agent_yaw = agent_lane_df['agent_yaw'].values\n",
    "        self.agent_coord = agent_lane_df['agent_coord'].values\n",
    "        self.points_to_lane_end = agent_lane_df['points_to_lane_end'].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        row_i = self.valid_indices[index]                        \n",
    "        valid_hist_len = self.valid_hist_len[row_i] \n",
    "        \n",
    "        lanes_seq_ = self.lane_vocab_idx[row_i - valid_hist_len + 1:row_i + 1]\n",
    "        speed_seq_ = self.agent_speed[row_i - valid_hist_len + 1:row_i + 1]\n",
    "        yaw_seq_ = self.agent_yaw[row_i - valid_hist_len + 1:row_i + 1]\n",
    "        points_to_lane_end_ = self.points_to_lane_end[row_i - valid_hist_len + 1:row_i + 1]\n",
    "        agent_coord_ = self.agent_coord[row_i - valid_hist_len + 1:row_i + 1]\n",
    "                \n",
    "        # padding\n",
    "        padding_len = self.history_len - valid_hist_len\n",
    "        lanes_seq = np.concatenate((lanes_seq_, self.PAD_TOKEN_IDX*np.ones(padding_len))).astype(np.int) # shouldn't get to PAD_TOKEN_IDX, just in case\n",
    "        speed_seq = np.concatenate((speed_seq_, np.zeros(padding_len))).astype(np.float32)\n",
    "        yaw_seq = np.concatenate((yaw_seq_, np.zeros(padding_len))).astype(np.float32)\n",
    "        points_to_lane_end = np.concatenate((points_to_lane_end_, np.zeros(padding_len))).astype(np.float32)\n",
    "        agent_coord = np.concatenate((np.vstack(agent_coord_), np.zeros((padding_len, 2)))).astype(np.float32)\n",
    "        hist_availabilities = np.concatenate((np.ones(valid_hist_len), np.zeros(padding_len))).astype(np.float32)\n",
    "\n",
    "        \n",
    "        # targets  \n",
    "        gt_coord_ = self.agent_coord[row_i + 1:row_i + self.valid_future_len[row_i] + 1]\n",
    "        valid_future_len = len(gt_coord_)\n",
    "        future_padding_len = self.future_len - valid_future_len\n",
    "        gt_coord = np.concatenate((np.vstack(gt_coord_), np.zeros((future_padding_len, 2)))).astype(np.float32)\n",
    "        gt_coord_availabilities = np.concatenate((np.ones(valid_future_len), np.zeros(future_padding_len))).astype(np.float32)\n",
    "        gt_lanes_seq_ = self.lane_vocab_idx[row_i + 1:row_i + valid_future_len + 1]\n",
    "        gt_lanes_seq = np.concatenate((gt_lanes_seq_, self.PAD_TOKEN_IDX*np.ones(future_padding_len))).astype(np.int)\n",
    "        gt_speed_ = self.agent_speed[row_i + 1:row_i + valid_future_len + 1]\n",
    "        gt_speed = np.concatenate((gt_speed_, np.zeros(future_padding_len))).astype(np.float32)\n",
    "        gt_yaw_ = self.agent_yaw[row_i + 1:row_i + valid_future_len + 1]\n",
    "        gt_yaw = np.concatenate((gt_yaw_, np.zeros(future_padding_len))).astype(np.float32)  \n",
    "        gt_points_to_lane_end_ = self.points_to_lane_end[row_i + 1:row_i + self.valid_future_len[row_i] + 1]\n",
    "        gt_points_to_lane_end = np.concatenate((gt_points_to_lane_end_, np.zeros(future_padding_len))).astype(np.float32)  \n",
    "        \n",
    "        return (lanes_seq, points_to_lane_end, speed_seq, yaw_seq, agent_coord, valid_hist_len, hist_availabilities, \n",
    "                gt_lanes_seq, gt_points_to_lane_end, valid_future_len, gt_coord, gt_speed, gt_yaw, gt_coord_availabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_indices(agent_lane_df, min_hist_len=10): # min_hist_len in addition to the current timestamp\n",
    "\n",
    "    has_enough_hist = agent_lane_df['the_same_agent_prev'].rolling(min_hist_len).sum() == min_hist_len\n",
    "    \n",
    "    valid_rows_bool = (agent_lane_df['the_same_agent_next'] & has_enough_hist)\n",
    "    return np.arange(len(agent_lane_df))[valid_rows_bool]\n",
    "\n",
    "\n",
    "def get_dataloader(agent_lane_df, map_segment_idx, shuffle=True, batch_size=1024, num_workers=7):\n",
    "    agent_lane_df_map_segment = agent_lane_df[agent_lane_df['map_segment_group'] == map_segment_idx]\n",
    "    valid_indices_map_segment = get_valid_indices(agent_lane_df_map_segment)\n",
    "    required_columns = ['valid_hist_len', 'valid_future_len', 'lane_vocab_idx', \n",
    "                        'agent_speed', 'agent_yaw', 'agent_coord', 'points_to_lane_end']\n",
    "    dataset = LaneSeqDataset(agent_lane_df_map_segment[required_columns],\n",
    "                             valid_indices_map_segment,\n",
    "                             len(map_segment_2_train_vocab[map_segment_idx]))\n",
    "    dataloader = DataLoader(dataset, shuffle=shuffle, batch_size=batch_size, num_workers=num_workers)\n",
    "    return dataloader\n",
    "          \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_segment_idx = 4\n",
    "# agent_lane_df = agent_lane_df_val\n",
    "# agent_lane_df_map_segment = agent_lane_df[agent_lane_df['map_segment_group'] == map_segment_idx]\n",
    "# valid_indices_map_segment = get_valid_indices(agent_lane_df_map_segment)\n",
    "# required_columns = ['valid_hist_len', 'valid_future_len', 'lane_vocab_idx', \n",
    "#                     'agent_speed', 'agent_yaw', 'agent_coord', 'points_to_lane_end']\n",
    "# dataset = LaneSeqDataset(agent_lane_df_map_segment[required_columns],\n",
    "#                          valid_indices_map_segment,\n",
    "#                          len(map_segment_2_train_vocab[map_segment_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/masked_cross_entropy.py\n",
    "import torch\n",
    "from torch.nn import functional\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def sequence_mask(sequence_length, max_len=None):\n",
    "    if max_len is None:\n",
    "        max_len = sequence_length.data.max()\n",
    "    batch_size = sequence_length.size(0)\n",
    "    seq_range = torch.range(0, max_len - 1).long()\n",
    "    seq_range_expand = seq_range.unsqueeze(0).expand(batch_size, max_len)\n",
    "    seq_range_expand = Variable(seq_range_expand)\n",
    "    if sequence_length.is_cuda:\n",
    "        seq_range_expand = seq_range_expand.cuda()\n",
    "    seq_length_expand = (sequence_length.unsqueeze(1)\n",
    "                         .expand_as(seq_range_expand))\n",
    "    return seq_range_expand < seq_length_expand\n",
    "\n",
    "\n",
    "def masked_cross_entropy(probs, target, length):\n",
    "#     length = Variable(torch.LongTensor(length)).cuda()\n",
    "\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        logits: A Variable containing a FloatTensor of size\n",
    "            (batch, max_len, num_classes) which contains the\n",
    "            unnormalized probability for each class.\n",
    "        target: A Variable containing a LongTensor of size\n",
    "            (batch, max_len) which contains the index of the true\n",
    "            class for each corresponding step.\n",
    "        length: A Variable containing a LongTensor of size (batch,)\n",
    "            which contains the length of each data in a batch.\n",
    "    Returns:\n",
    "        loss: An average loss value masked by the length.\n",
    "    \"\"\"\n",
    "\n",
    "    # logits_flat: (batch * max_len, num_classes)\n",
    "#     logits_flat = logits.view(-1, logits.size(-1))\n",
    "    # log_probs_flat: (batch * max_len, num_classes)\n",
    "    log_probs_flat = torch.log(probs).view(-1, probs.size(-1))#functional.log_softmax(logits_flat)\n",
    "    # target_flat: (batch * max_len, 1)\n",
    "    target_flat = target.view(-1, 1)\n",
    "    # losses_flat: (batch * max_len, 1)\n",
    "    losses_flat = -torch.gather(log_probs_flat, dim=1, index=target_flat)\n",
    "    # losses: (batch, max_len)\n",
    "    losses = losses_flat.view(*target.size())\n",
    "    # mask: (batch, max_len)\n",
    "    mask = sequence_mask(sequence_length=length, max_len=target.size(1))\n",
    "    losses = losses * mask.float()\n",
    "    loss = losses.sum() / length.float().sum()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_segment_idx = MAP_SEGMENT_I\n",
    "dataloader_trn = get_dataloader(agent_lane_df_trn, map_segment_idx=map_segment_idx, \n",
    "                                batch_size=700, num_workers=16)\n",
    "dataloader_val = get_dataloader(agent_lane_df_val, map_segment_idx=map_segment_idx, shuffle=False, batch_size=256)\n",
    "lane_seq_model = LaneSeqModel(map_segment_2_train_vocab[map_segment_idx], \n",
    "                              embedding_dim=128,\n",
    "                              hidden_dim_lane_lstm=64,\n",
    "                             hidden_dim_speed_lstm=64,\n",
    "                             hidden_dim_coord_lstm=64,\n",
    "                              bidirectional_speed_lstm=False,\n",
    "                             n_layers_lane_lstm=2,\n",
    "                             n_layers_speed_lstm=2,\n",
    "                             n_layers_coord_lstm=1,\n",
    "                             map_segment=4,\n",
    "                             dropout=0,\n",
    "                              device=device).to(device)\n",
    "\n",
    "#https://discuss.pytorch.org/t/how-the-pytorch-freeze-network-in-some-layers-only-the-rest-of-the-training/7088/15?u=raman_samusevich\n",
    "def dfs_freeze(model, names_to_exclude=set()):\n",
    "    for name, child in model.named_children():\n",
    "        if name not in names_to_exclude:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "            dfs_freeze(child)\n",
    "            \n",
    "def dfs_unfreeze(model, names_to_exclude=set()):\n",
    "    for name, child in model.named_children():\n",
    "        if name not in names_to_exclude:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True\n",
    "            dfs_unfreeze(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dbcef5ed7504fa6804d639c143ea83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1506.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blitzinit finished\n",
      "Init without coord-opt finished\n",
      "Aggressive coord-related init finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534edde858e34cc381881defea725a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ep. 0, Avg val losses. CE: 0.59440, neg_loglik: 30.4), neg_loglik lanes: 83.9), neg_loglik speed: 35.3)\n",
      "loss_mse_points_to_lane_end: 10, mse_speed: 1.60, mse_yaw: 0.61\n",
      "Validation loss decreased (inf --> 30.377873).  Saving model ...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch end\n",
      "Ep. 1, Avg train loss: 816.74895 (ce: 0.90981, neg_loglik: 3667.6)\n",
      "loss_mse_points_to_lane_end: 31, mse_speed: 2.57, mse_yaw: 0.53\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759da411eec04711a8fea1a03b3ace63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ep. 1, Avg val losses. CE: 0.78720, neg_loglik: 20.1), neg_loglik lanes: 73.5), neg_loglik speed: 35.3)\n",
      "loss_mse_points_to_lane_end: 32, mse_speed: 1.60, mse_yaw: 0.61\n",
      "Validation loss decreased (30.377873 --> 20.123980).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34dc90ba40643999f9a2bb75b96b1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1506.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def train(lane_seq_model, dataloader_trn, dataloader_val, epochs_max=5):\n",
    "epochs_max=5\n",
    "progress_bar = tqdm(dataloader_trn)\n",
    "iterator = iter(progress_bar)\n",
    "epoch = 0\n",
    "early_stopping = EarlyStopping(patience=7, verbose=True, path=f'map_segment_{map_segment_idx}_combined_loss_checkpoint.pt')\n",
    "\n",
    "mse=nn.MSELoss(reduction=\"none\")\n",
    "clip_value=2\n",
    "\n",
    "losses_train = []\n",
    "losses_ce = []\n",
    "losses_neg_loglik = []\n",
    "losses_mse_points_to_lane_end = []\n",
    "losses_mse_speed = []\n",
    "losses_mse_yaw = []\n",
    "\n",
    "############# helping funcs ###################\n",
    "###############################################\n",
    "def process_next_train_iters(losses_weights, optimizer, iters_count=None, epochs_max=None, use_coord_selfpredictions=False):\n",
    "    global progress_bar, iterator, losses_train, losses_ce, losses_neg_loglik, losses_mse_points_to_lane_end, losses_mse_speed, losses_mse_yaw, epoch\n",
    "    assert (iters_count is None) != (epochs_max is None)\n",
    "    if epochs_max is not None:\n",
    "        iter_incr = 0\n",
    "        iters_count = 2\n",
    "    else:\n",
    "        iter_incr = 1\n",
    "    i = 0\n",
    "    while i < iters_count:\n",
    "        i += iter_incr\n",
    "        batch = next(iterator, None)\n",
    "        if batch is None:\n",
    "            print('Epoch end')\n",
    "            epoch += 1\n",
    "            print(f\"Ep. {epoch}, Avg train loss: {np.mean(losses_train):.5f} (ce: {np.mean(losses_ce):.5f}, neg_loglik: {np.mean(losses_neg_loglik):.1f})\\nloss_mse_points_to_lane_end: {np.mean(losses_mse_points_to_lane_end):.0f}, mse_speed: {np.mean(losses_mse_speed):.2f}, mse_yaw: {np.mean(losses_mse_yaw):.2f}\")\n",
    "            eval_on_val()\n",
    "            if early_stopping.early_stop:\n",
    "                break            \n",
    "            if epochs_max is not None and epoch >= epochs_max:\n",
    "                break\n",
    "            progress_bar = tqdm(dataloader_trn)\n",
    "            iterator = iter(progress_bar)\n",
    "            batch = next(iterator, None)\n",
    "            losses_train = []\n",
    "            losses_ce = []\n",
    "            losses_neg_loglik = []\n",
    "            losses_mse_points_to_lane_end = []\n",
    "            losses_mse_speed = []\n",
    "            losses_mse_yaw = []\n",
    "\n",
    "        # moving to GPU if available\n",
    "        (lanes_seq, points_to_lane_end, speed_seq, yaw_seq, agent_coord, valid_hist_len, hist_availabilities,\n",
    "         gt_lanes_seq, gt_points_to_lane_end, gt_valid_future_len, gt_coord, gt_speed, \n",
    "         gt_yaw, gt_coord_availabilities) = [x.to(device) for x in batch]\n",
    "#         print('input nans', torch.sum(torch.isnan(agent_coord)))\n",
    "        lane_seq_model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "        (input_pred_next_lane_prob, input_pred_next_dist_to_lane_end, \n",
    "         input_pred_next_speed_yaw, \n",
    "         input_pred_next_coord, input_coord_estimation_lane_pred, input_pred_coordinates_from_speed,\n",
    "         pred_lane_prob, pred_points_to_lane_end_seq, \n",
    "         pred_speed, pred_yaw, \n",
    "         pred_coordinates, pred_coordinates_from_lanes, pred_coordinates_from_speed) = lane_seq_model(lanes_seq, points_to_lane_end, speed_seq,\n",
    "                                                                  yaw_seq, agent_coord, valid_hist_len, return_prediction_on_input=True,\n",
    "                                                                                                      use_coord_selfpredictions=use_coord_selfpredictions)\n",
    "\n",
    "        loss_ce_with_teacher = masked_cross_entropy(input_pred_next_lane_prob, lanes_seq, valid_hist_len)\n",
    "        loss_ce = masked_cross_entropy(pred_lane_prob, gt_lanes_seq, gt_valid_future_len)\n",
    "\n",
    "        loss_neg_loglik_with_teacher = (0.5*mse(input_pred_next_coord, agent_coord).sum(dim=-1)*hist_availabilities).sum()/hist_availabilities.sum()\n",
    "        loss_neg_loglik = (0.5*mse(pred_coordinates, gt_coord).sum(dim=-1)*gt_coord_availabilities).sum()/gt_coord_availabilities.sum()\n",
    "\n",
    "        loss_neg_loglik_with_teacher_based_on_lanes = (0.5*mse(input_coord_estimation_lane_pred, agent_coord).sum(dim=-1)*hist_availabilities).sum()/hist_availabilities.sum()\n",
    "        loss_neg_loglik_based_on_lanes = (0.5*mse(pred_coordinates_from_lanes, gt_coord).sum(dim=-1)*gt_coord_availabilities).sum()/gt_coord_availabilities.sum()\n",
    "\n",
    "        loss_neg_loglik_with_teacher_from_speed = (0.5*mse(input_pred_coordinates_from_speed, agent_coord).sum(dim=-1)*hist_availabilities).sum()/hist_availabilities.sum()\n",
    "        loss_neg_loglik_from_speed = (0.5*mse(pred_coordinates_from_speed, gt_coord).sum(dim=-1)*gt_coord_availabilities).sum()/gt_coord_availabilities.sum()\n",
    "\n",
    "        loss_mse_speed_with_teacher = (mse(input_pred_next_speed_yaw[:, :, 0], speed_seq)*hist_availabilities).sum()/hist_availabilities.sum()\n",
    "        loss_mse_speed = (mse(pred_speed, gt_speed)*gt_coord_availabilities).sum()/gt_coord_availabilities.sum()\n",
    "\n",
    "        loss_mse_yaw_with_teacher = (mse(input_pred_next_speed_yaw[:, :, 1], yaw_seq)*hist_availabilities).sum()/hist_availabilities.sum()\n",
    "        loss_mse_yaw = (mse(pred_yaw, gt_yaw)*gt_coord_availabilities).sum()/gt_coord_availabilities.sum()\n",
    "\n",
    "        loss_mse_points_to_lane_end_teacher = (mse(input_pred_next_dist_to_lane_end.squeeze(), points_to_lane_end)*hist_availabilities).sum()/hist_availabilities.sum()\n",
    "        loss_mse_points_to_lane_end = (mse(pred_points_to_lane_end_seq, gt_points_to_lane_end)*gt_coord_availabilities).sum()/gt_coord_availabilities.sum()\n",
    "\n",
    "#         loss = (loss_ce_with_teacher + loss_ce + (loss_mse_speed_with_teacher + \n",
    "#                 loss_mse_speed)/5 + loss_mse_yaw_with_teacher +  loss_mse_yaw + \n",
    "#                 (loss_mse_points_to_lane_end_teacher +  loss_mse_points_to_lane_end)/20)\n",
    "#             + \n",
    "#                     loss_neg_loglik_with_teacher_based_on_lanes, \n",
    "#                            loss_neg_loglik_based_on_lanes, \n",
    "#                            loss_neg_loglik_with_teacher_from_speed\n",
    "        losses_list = [loss_ce_with_teacher, \n",
    "                       loss_ce,\n",
    "                       loss_mse_speed_with_teacher, \n",
    "                       loss_mse_speed,\n",
    "                       loss_mse_yaw_with_teacher, \n",
    "                       loss_mse_yaw,\n",
    "                       loss_mse_points_to_lane_end_teacher, \n",
    "                       loss_mse_points_to_lane_end, \n",
    "                       loss_neg_loglik_with_teacher_based_on_lanes, \n",
    "                       loss_neg_loglik_based_on_lanes, \n",
    "                       loss_neg_loglik_with_teacher_from_speed,\n",
    "                       loss_neg_loglik_from_speed, \n",
    "                       loss_neg_loglik_with_teacher,\n",
    "                       loss_neg_loglik]\n",
    "#             print('losses_list', losses_list)\n",
    "        loss = sum([loss_ * weight_ \n",
    "                    for loss_, weight_ in zip(losses_list, losses_weights) \n",
    "                    if weight_ > 0\n",
    "                   ])\n",
    "    \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "#             print('clip_value', clip_value)\n",
    "        nn.utils.clip_grad_norm_(lane_seq_model.parameters(), clip_value)\n",
    "        optimizer.step()\n",
    "\n",
    "        losses_train.append(loss.item())\n",
    "        losses_ce.append(loss_ce.item())\n",
    "        losses_neg_loglik.append(loss_neg_loglik.item())            \n",
    "        losses_mse_points_to_lane_end.append(loss_mse_points_to_lane_end.item())\n",
    "        losses_mse_speed.append(loss_mse_speed.item())\n",
    "        losses_mse_yaw.append(loss_mse_yaw.item())\n",
    "        progress_bar.set_description(f\"E{epoch},{loss.item():.2f} ({loss_ce.item():.2f},{loss_neg_loglik.item():.1f}/{loss_neg_loglik_based_on_lanes.item():.0f}|{loss_neg_loglik_from_speed.item(): .0f}|{loss_neg_loglik_with_teacher_from_speed.item():.0f}){loss_mse_points_to_lane_end.item():.0f},{loss_mse_speed.item():.2f},{loss_mse_yaw.item():.2f}\")\n",
    "\n",
    "\n",
    "def eval_on_val():\n",
    "    lane_seq_model.eval()\n",
    "\n",
    "    losses_ce = []\n",
    "    losses_neg_loglik = []\n",
    "    losses_neg_loglik_based_on_lanes = []\n",
    "    losses_neg_loglik_from_speed = []\n",
    "    losses_mse_points_to_lane_end = []\n",
    "    losses_mse_speed = []\n",
    "    losses_mse_yaw = []\n",
    "    for batch in tqdm(dataloader_val):\n",
    "\n",
    "        # moving to GPU if available\n",
    "        (lanes_seq, points_to_lane_end, speed_seq, yaw_seq, agent_coord, valid_hist_len, hist_availabilities,\n",
    "         gt_lanes_seq, gt_points_to_lane_end, gt_valid_future_len, gt_coord, gt_speed, \n",
    "         gt_yaw, gt_coord_availabilities) = [x.to(device) for x in batch]\n",
    "\n",
    "        (pred_lane_prob, pred_points_to_lane_end_seq, \n",
    "         pred_speed, pred_yaw, \n",
    "         pred_coordinates, pred_coordinates_from_lanes, pred_coordinates_from_speed) = lane_seq_model(lanes_seq, points_to_lane_end, speed_seq,\n",
    "                                                                  yaw_seq, agent_coord, valid_hist_len, return_prediction_on_input=False)\n",
    "\n",
    "        loss_ce = masked_cross_entropy(pred_lane_prob, gt_lanes_seq, gt_valid_future_len)\n",
    "        loss_neg_loglik = (0.5*mse(pred_coordinates, gt_coord).sum(dim=-1)*gt_coord_availabilities).sum()/gt_coord_availabilities.sum()\n",
    "        loss_neg_loglik_based_on_lanes = (0.5*mse(pred_coordinates_from_lanes, gt_coord).sum(dim=-1)*gt_coord_availabilities).sum()/gt_coord_availabilities.sum()\n",
    "        loss_neg_loglik_from_speed = (0.5*mse(pred_coordinates_from_speed, gt_coord).sum(dim=-1)*gt_coord_availabilities).sum()/gt_coord_availabilities.sum()\n",
    "        loss_mse_speed = (mse(pred_speed, gt_speed)*gt_coord_availabilities).sum()/gt_coord_availabilities.sum()\n",
    "        loss_mse_yaw = (mse(pred_yaw, gt_yaw)*gt_coord_availabilities).sum()/gt_coord_availabilities.sum()\n",
    "        loss_mse_points_to_lane_end = (mse(pred_points_to_lane_end_seq, gt_points_to_lane_end)*gt_coord_availabilities).sum()/gt_coord_availabilities.sum()\n",
    "\n",
    "        losses_ce.append(loss_ce.item())\n",
    "        losses_neg_loglik.append(loss_neg_loglik.item()) \n",
    "        losses_neg_loglik_based_on_lanes.append(loss_neg_loglik_based_on_lanes.item()) \n",
    "        losses_neg_loglik_from_speed.append(loss_neg_loglik_from_speed.item()) \n",
    "        losses_mse_points_to_lane_end.append(loss_mse_points_to_lane_end.item())\n",
    "        losses_mse_speed.append(loss_mse_speed.item())\n",
    "        losses_mse_yaw.append(loss_mse_yaw.item())\n",
    "        progress_bar.set_description(f\"({loss_ce.item():.2f},{loss_neg_loglik.item():.1f}/{loss_neg_loglik_based_on_lanes.item():.0f}|{loss_neg_loglik_from_speed.item(): .0f}){loss_mse_points_to_lane_end.item():.0f},{loss_mse_speed.item():.2f},{loss_mse_yaw.item():.2f}\")\n",
    "    print(f\"Ep. {epoch}, Avg val losses. CE: {np.mean(losses_ce):.5f}, neg_loglik: {np.mean(losses_neg_loglik):.1f}), neg_loglik lanes: {np.mean(losses_neg_loglik_based_on_lanes):.1f}), neg_loglik speed: {np.mean(losses_neg_loglik_from_speed):.1f})\\nloss_mse_points_to_lane_end: {np.mean(losses_mse_points_to_lane_end):.0f}, mse_speed: {np.mean(losses_mse_speed):.2f}, mse_yaw: {np.mean(losses_mse_yaw):.2f}\")\n",
    "    lr_scheduler.step(np.mean(losses_neg_loglik))\n",
    "    early_stopping(np.mean(losses_neg_loglik), lane_seq_model) \n",
    "\n",
    "#############################################\n",
    "############# learning schedule #############\n",
    "blitzinit_loss_weights = torch.ones(14)\n",
    "blitzinit_loss_weights[-6:] = 0\n",
    "# speed\n",
    "blitzinit_loss_weights[2:4] /= 5\n",
    "# lane to end\n",
    "blitzinit_loss_weights[6:8] /= 20\n",
    "blitzinit_batches_count = 150\n",
    "blitzinit_lr = 3e-2\n",
    "\n",
    "init_no_coord_loss_weights = torch.ones(14)\n",
    "init_no_coord_loss_weights[-6:] = 0\n",
    "init_no_coord_batches_count = 100\n",
    "init_no_coord_lr = 1e-2\n",
    "\n",
    "aggressive_coord_init_loss_weights = torch.zeros(14)\n",
    "aggressive_coord_init_loss_weights[-2:] = 1\n",
    "aggressive_coord_init_batches_count = 150\n",
    "aggressive_coord_init_lr = 3e-2\n",
    "\n",
    "final_loss_weights = torch.ones(14)/30\n",
    "final_loss_weights[:2] = 5\n",
    "final_loss_weights[-6:-4] /= 100\n",
    "final_loss_weights[-2:] = 1\n",
    "lr_after_init = 3e-4\n",
    "\n",
    "\n",
    "# blitzinit\n",
    "optimizer = optim.Adam(lane_seq_model.parameters(), lr=blitzinit_lr)\n",
    "process_next_train_iters(blitzinit_loss_weights, optimizer, iters_count=blitzinit_batches_count)\n",
    "print('Blitzinit finished')\n",
    "\n",
    "# further init without coord optimization\n",
    "optimizer = optim.Adam(lane_seq_model.parameters(), lr=init_no_coord_lr)\n",
    "process_next_train_iters(init_no_coord_loss_weights, optimizer, iters_count=init_no_coord_batches_count)\n",
    "print('Init without coord-opt finished')\n",
    "\n",
    "# aggressive coord-layers init\n",
    "dfs_freeze(lane_seq_model, {'fc_coord', 'bn_1', 'fc_coord_hidden', 'bn_2', 'lstm_coord'})   \n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, lane_seq_model.parameters()), lr=aggressive_coord_init_lr)\n",
    "process_next_train_iters(aggressive_coord_init_loss_weights, optimizer, iters_count=aggressive_coord_init_batches_count)\n",
    "print('Aggressive coord-related init finished')\n",
    "\n",
    "dfs_unfreeze(lane_seq_model)\n",
    "\n",
    "def clip_and_replace_explosures(grad):\n",
    "    grad[torch.logical_or(torch.isnan(grad), torch.isinf(grad))] = torch.tensor(0.0).to(device)\n",
    "#     grad = torch.clamp(grad, -0.25, 0.25)\n",
    "    return grad\n",
    "\n",
    "for param in lane_seq_model.parameters():\n",
    "    if param.requires_grad:\n",
    "        param.register_hook(clip_and_replace_explosures)\n",
    "                \n",
    "optimizer = optim.Adam(lane_seq_model.parameters(), lr=lr_after_init)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=3)\n",
    "eval_on_val()\n",
    "process_next_train_iters(final_loss_weights, optimizer, epochs_max=epochs_max, use_coord_selfpredictions=True)\n",
    "    \n",
    "# train(lane_seq_model, dataloader_trn, dataloader_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
